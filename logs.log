2024-07-10 16:56:44,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-10 16:56:44,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-10 16:56:44,450:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-10 16:56:44,450:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-10 16:57:31,584:INFO:PyCaret ClassificationExperiment
2024-07-10 16:57:31,584:INFO:Logging name: clf-default-name
2024-07-10 16:57:31,584:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-10 16:57:31,584:INFO:version 3.3.2
2024-07-10 16:57:31,584:INFO:Initializing setup()
2024-07-10 16:57:31,584:INFO:self.USI: a103
2024-07-10 16:57:31,584:INFO:self._variable_keys: {'n_jobs_param', 'pipeline', 'y_train', 'idx', 'fold_shuffle_param', '_available_plots', '_ml_usecase', 'fix_imbalance', 'memory', 'exp_name_log', 'log_plots_param', 'X_train', 'gpu_n_jobs_param', 'seed', 'USI', 'html_param', 'X', 'data', 'X_test', 'logging_param', 'y_test', 'target_param', 'exp_id', 'y', 'fold_generator', 'is_multiclass', 'gpu_param', 'fold_groups_param'}
2024-07-10 16:57:31,584:INFO:Checking environment
2024-07-10 16:57:31,585:INFO:python_version: 3.10.14
2024-07-10 16:57:31,585:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-07-10 16:57:31,585:INFO:machine: AMD64
2024-07-10 16:57:31,585:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-10 16:57:31,591:INFO:Memory: svmem(total=34004869120, available=17250377728, percent=49.3, used=16754491392, free=17250377728)
2024-07-10 16:57:31,591:INFO:Physical Core: 16
2024-07-10 16:57:31,591:INFO:Logical Core: 22
2024-07-10 16:57:31,591:INFO:Checking libraries
2024-07-10 16:57:31,591:INFO:System:
2024-07-10 16:57:31,591:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-07-10 16:57:31,591:INFO:executable: c:\Users\Admin\miniconda3\envs\gumi_env310\python.exe
2024-07-10 16:57:31,591:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-10 16:57:31,591:INFO:PyCaret required dependencies:
2024-07-10 16:57:31,620:INFO:                 pip: 24.0
2024-07-10 16:57:31,620:INFO:          setuptools: 69.5.1
2024-07-10 16:57:31,620:INFO:             pycaret: 3.3.2
2024-07-10 16:57:31,620:INFO:             IPython: 8.25.0
2024-07-10 16:57:31,621:INFO:          ipywidgets: 8.1.3
2024-07-10 16:57:31,621:INFO:                tqdm: 4.66.4
2024-07-10 16:57:31,621:INFO:               numpy: 1.26.4
2024-07-10 16:57:31,621:INFO:              pandas: 2.1.4
2024-07-10 16:57:31,621:INFO:              jinja2: 3.1.4
2024-07-10 16:57:31,621:INFO:               scipy: 1.11.4
2024-07-10 16:57:31,621:INFO:              joblib: 1.3.2
2024-07-10 16:57:31,621:INFO:             sklearn: 1.4.2
2024-07-10 16:57:31,621:INFO:                pyod: 2.0.1
2024-07-10 16:57:31,621:INFO:            imblearn: 0.12.3
2024-07-10 16:57:31,621:INFO:   category_encoders: 2.6.3
2024-07-10 16:57:31,621:INFO:            lightgbm: 4.4.0
2024-07-10 16:57:31,621:INFO:               numba: 0.60.0
2024-07-10 16:57:31,621:INFO:            requests: 2.32.3
2024-07-10 16:57:31,621:INFO:          matplotlib: 3.7.5
2024-07-10 16:57:31,621:INFO:          scikitplot: 0.3.7
2024-07-10 16:57:31,621:INFO:         yellowbrick: 1.5
2024-07-10 16:57:31,621:INFO:              plotly: 5.22.0
2024-07-10 16:57:31,621:INFO:    plotly-resampler: Not installed
2024-07-10 16:57:31,621:INFO:             kaleido: 0.2.1
2024-07-10 16:57:31,621:INFO:           schemdraw: 0.15
2024-07-10 16:57:31,621:INFO:         statsmodels: 0.14.2
2024-07-10 16:57:31,621:INFO:              sktime: 0.26.0
2024-07-10 16:57:31,621:INFO:               tbats: 1.1.3
2024-07-10 16:57:31,621:INFO:            pmdarima: 2.0.4
2024-07-10 16:57:31,621:INFO:              psutil: 5.9.8
2024-07-10 16:57:31,621:INFO:          markupsafe: 2.1.5
2024-07-10 16:57:31,621:INFO:             pickle5: Not installed
2024-07-10 16:57:31,621:INFO:         cloudpickle: 3.0.0
2024-07-10 16:57:31,621:INFO:         deprecation: 2.1.0
2024-07-10 16:57:31,621:INFO:              xxhash: 3.4.1
2024-07-10 16:57:31,621:INFO:           wurlitzer: Not installed
2024-07-10 16:57:31,621:INFO:PyCaret optional dependencies:
2024-07-10 16:57:31,685:INFO:                shap: Not installed
2024-07-10 16:57:31,685:INFO:           interpret: Not installed
2024-07-10 16:57:31,685:INFO:                umap: Not installed
2024-07-10 16:57:31,685:INFO:     ydata_profiling: Not installed
2024-07-10 16:57:31,685:INFO:  explainerdashboard: Not installed
2024-07-10 16:57:31,685:INFO:             autoviz: Not installed
2024-07-10 16:57:31,685:INFO:           fairlearn: Not installed
2024-07-10 16:57:31,685:INFO:          deepchecks: Not installed
2024-07-10 16:57:31,685:INFO:             xgboost: 2.1.0
2024-07-10 16:57:31,685:INFO:            catboost: Not installed
2024-07-10 16:57:31,685:INFO:              kmodes: Not installed
2024-07-10 16:57:31,685:INFO:             mlxtend: Not installed
2024-07-10 16:57:31,685:INFO:       statsforecast: Not installed
2024-07-10 16:57:31,685:INFO:        tune_sklearn: Not installed
2024-07-10 16:57:31,685:INFO:                 ray: Not installed
2024-07-10 16:57:31,685:INFO:            hyperopt: Not installed
2024-07-10 16:57:31,685:INFO:              optuna: 3.6.1
2024-07-10 16:57:31,685:INFO:               skopt: Not installed
2024-07-10 16:57:31,685:INFO:              mlflow: Not installed
2024-07-10 16:57:31,685:INFO:              gradio: Not installed
2024-07-10 16:57:31,685:INFO:             fastapi: Not installed
2024-07-10 16:57:31,685:INFO:             uvicorn: Not installed
2024-07-10 16:57:31,685:INFO:              m2cgen: Not installed
2024-07-10 16:57:31,686:INFO:           evidently: Not installed
2024-07-10 16:57:31,686:INFO:               fugue: Not installed
2024-07-10 16:57:31,686:INFO:           streamlit: Not installed
2024-07-10 16:57:31,686:INFO:             prophet: Not installed
2024-07-10 16:57:31,686:INFO:None
2024-07-10 16:57:31,686:INFO:Set up data.
2024-07-10 16:57:31,765:INFO:Set up folding strategy.
2024-07-10 16:57:31,765:INFO:Set up train/test split.
2024-07-10 17:03:09,348:INFO:PyCaret RegressionExperiment
2024-07-10 17:03:09,349:INFO:Logging name: reg-default-name
2024-07-10 17:03:09,349:INFO:ML Usecase: MLUsecase.REGRESSION
2024-07-10 17:03:09,349:INFO:version 3.3.2
2024-07-10 17:03:09,349:INFO:Initializing setup()
2024-07-10 17:03:09,349:INFO:self.USI: 3009
2024-07-10 17:03:09,349:INFO:self._variable_keys: {'n_jobs_param', 'pipeline', 'y_train', 'idx', 'fold_shuffle_param', '_available_plots', '_ml_usecase', 'memory', 'exp_name_log', 'log_plots_param', 'X_train', 'gpu_n_jobs_param', 'seed', 'USI', 'html_param', 'X', 'data', 'X_test', 'logging_param', 'y_test', 'target_param', 'transform_target_param', 'exp_id', 'y', 'fold_generator', 'gpu_param', 'fold_groups_param'}
2024-07-10 17:03:09,349:INFO:Checking environment
2024-07-10 17:03:09,349:INFO:python_version: 3.10.14
2024-07-10 17:03:09,349:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-07-10 17:03:09,349:INFO:machine: AMD64
2024-07-10 17:03:09,349:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-10 17:03:09,354:INFO:Memory: svmem(total=34004869120, available=17232310272, percent=49.3, used=16772558848, free=17232310272)
2024-07-10 17:03:09,355:INFO:Physical Core: 16
2024-07-10 17:03:09,355:INFO:Logical Core: 22
2024-07-10 17:03:09,355:INFO:Checking libraries
2024-07-10 17:03:09,355:INFO:System:
2024-07-10 17:03:09,355:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-07-10 17:03:09,355:INFO:executable: c:\Users\Admin\miniconda3\envs\gumi_env310\python.exe
2024-07-10 17:03:09,355:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-10 17:03:09,355:INFO:PyCaret required dependencies:
2024-07-10 17:03:09,355:INFO:                 pip: 24.0
2024-07-10 17:03:09,355:INFO:          setuptools: 69.5.1
2024-07-10 17:03:09,355:INFO:             pycaret: 3.3.2
2024-07-10 17:03:09,355:INFO:             IPython: 8.25.0
2024-07-10 17:03:09,355:INFO:          ipywidgets: 8.1.3
2024-07-10 17:03:09,355:INFO:                tqdm: 4.66.4
2024-07-10 17:03:09,355:INFO:               numpy: 1.26.4
2024-07-10 17:03:09,355:INFO:              pandas: 2.1.4
2024-07-10 17:03:09,355:INFO:              jinja2: 3.1.4
2024-07-10 17:03:09,355:INFO:               scipy: 1.11.4
2024-07-10 17:03:09,355:INFO:              joblib: 1.3.2
2024-07-10 17:03:09,355:INFO:             sklearn: 1.4.2
2024-07-10 17:03:09,355:INFO:                pyod: 2.0.1
2024-07-10 17:03:09,355:INFO:            imblearn: 0.12.3
2024-07-10 17:03:09,355:INFO:   category_encoders: 2.6.3
2024-07-10 17:03:09,355:INFO:            lightgbm: 4.4.0
2024-07-10 17:03:09,355:INFO:               numba: 0.60.0
2024-07-10 17:03:09,355:INFO:            requests: 2.32.3
2024-07-10 17:03:09,355:INFO:          matplotlib: 3.7.5
2024-07-10 17:03:09,355:INFO:          scikitplot: 0.3.7
2024-07-10 17:03:09,355:INFO:         yellowbrick: 1.5
2024-07-10 17:03:09,355:INFO:              plotly: 5.22.0
2024-07-10 17:03:09,355:INFO:    plotly-resampler: Not installed
2024-07-10 17:03:09,355:INFO:             kaleido: 0.2.1
2024-07-10 17:03:09,355:INFO:           schemdraw: 0.15
2024-07-10 17:03:09,355:INFO:         statsmodels: 0.14.2
2024-07-10 17:03:09,356:INFO:              sktime: 0.26.0
2024-07-10 17:03:09,356:INFO:               tbats: 1.1.3
2024-07-10 17:03:09,356:INFO:            pmdarima: 2.0.4
2024-07-10 17:03:09,356:INFO:              psutil: 5.9.8
2024-07-10 17:03:09,356:INFO:          markupsafe: 2.1.5
2024-07-10 17:03:09,356:INFO:             pickle5: Not installed
2024-07-10 17:03:09,356:INFO:         cloudpickle: 3.0.0
2024-07-10 17:03:09,356:INFO:         deprecation: 2.1.0
2024-07-10 17:03:09,356:INFO:              xxhash: 3.4.1
2024-07-10 17:03:09,356:INFO:           wurlitzer: Not installed
2024-07-10 17:03:09,356:INFO:PyCaret optional dependencies:
2024-07-10 17:03:09,356:INFO:                shap: Not installed
2024-07-10 17:03:09,356:INFO:           interpret: Not installed
2024-07-10 17:03:09,356:INFO:                umap: Not installed
2024-07-10 17:03:09,356:INFO:     ydata_profiling: Not installed
2024-07-10 17:03:09,356:INFO:  explainerdashboard: Not installed
2024-07-10 17:03:09,356:INFO:             autoviz: Not installed
2024-07-10 17:03:09,356:INFO:           fairlearn: Not installed
2024-07-10 17:03:09,356:INFO:          deepchecks: Not installed
2024-07-10 17:03:09,356:INFO:             xgboost: 2.1.0
2024-07-10 17:03:09,356:INFO:            catboost: Not installed
2024-07-10 17:03:09,356:INFO:              kmodes: Not installed
2024-07-10 17:03:09,356:INFO:             mlxtend: Not installed
2024-07-10 17:03:09,356:INFO:       statsforecast: Not installed
2024-07-10 17:03:09,356:INFO:        tune_sklearn: Not installed
2024-07-10 17:03:09,356:INFO:                 ray: Not installed
2024-07-10 17:03:09,356:INFO:            hyperopt: Not installed
2024-07-10 17:03:09,356:INFO:              optuna: 3.6.1
2024-07-10 17:03:09,356:INFO:               skopt: Not installed
2024-07-10 17:03:09,356:INFO:              mlflow: Not installed
2024-07-10 17:03:09,356:INFO:              gradio: Not installed
2024-07-10 17:03:09,356:INFO:             fastapi: Not installed
2024-07-10 17:03:09,356:INFO:             uvicorn: Not installed
2024-07-10 17:03:09,356:INFO:              m2cgen: Not installed
2024-07-10 17:03:09,356:INFO:           evidently: Not installed
2024-07-10 17:03:09,356:INFO:               fugue: Not installed
2024-07-10 17:03:09,356:INFO:           streamlit: Not installed
2024-07-10 17:03:09,356:INFO:             prophet: Not installed
2024-07-10 17:03:09,356:INFO:None
2024-07-10 17:03:09,356:INFO:Set up data.
2024-07-10 17:03:09,363:INFO:Set up folding strategy.
2024-07-10 17:03:09,363:INFO:Set up train/test split.
2024-07-10 17:03:09,374:INFO:Set up index.
2024-07-10 17:03:09,375:INFO:Assigning column types.
2024-07-10 17:03:09,378:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-10 17:03:09,378:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,381:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,384:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,419:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,441:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,443:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:09,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:09,445:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,447:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,449:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,486:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,512:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,513:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:09,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:09,515:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-07-10 17:03:09,517:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,519:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,554:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,577:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,578:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:09,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:09,583:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,586:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,620:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,648:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,649:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:09,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:09,650:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-07-10 17:03:09,655:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,695:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,722:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:09,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:09,728:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,765:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,788:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,788:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:09,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:09,790:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-07-10 17:03:09,830:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,855:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,855:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:09,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:09,900:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,922:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,923:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:09,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:09,924:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-10 17:03:09,961:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 17:03:09,989:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:09,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:10,030:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 17:03:10,055:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:10,056:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:10,056:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-07-10 17:03:10,121:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:10,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:10,187:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:10,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:10,193:INFO:Preparing preprocessing pipeline...
2024-07-10 17:03:10,193:INFO:Set up simple imputation.
2024-07-10 17:03:10,198:INFO:Set up encoding of ordinal features.
2024-07-10 17:03:10,199:INFO:Set up encoding of categorical features.
2024-07-10 17:03:10,200:INFO:Set up column name cleaning.
2024-07-10 17:03:10,316:INFO:Finished creating preprocessing pipeline.
2024-07-10 17:03:10,328:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Admin\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['연식(년)', '주행거리(km)', '배기량(cc)',
                                             '압류_저당', '통풍시트(1열/2열)', '전동식 트렁크',
                                             '스마트 크루즈 컨트롤', '가죽 시트',
                                             '전방 주차거리 경고', '열선시트(1열/2열)',
                                             '후측방 경보 시스템', '내비게이션', '선루프',
                                             '후방 모니터', '옵션_갯수'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              f...
                                    include=['차종', '연료', '변속기', '색상_중분류'],
                                    transformer=OneHotEncoder(cols=['차종', '연료',
                                                                    '변속기',
                                                                    '색상_중분류'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-07-10 17:03:10,328:INFO:Creating final display dataframe.
2024-07-10 17:03:10,582:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                가격
2                   Target type        Regression
3           Original data shape        (1760, 23)
4        Transformed data shape        (1760, 52)
5   Transformed train set shape        (1232, 52)
6    Transformed test set shape         (528, 52)
7               Ignore features                 2
8              Numeric features                15
9          Categorical features                 5
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              3009
2024-07-10 17:03:10,654:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:10,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:10,722:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 17:03:10,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 17:03:10,723:INFO:setup() successfully completed in 1.38s...............
2024-07-10 17:03:10,724:INFO:Initializing compare_models()
2024-07-10 17:03:10,724:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-07-10 17:03:10,724:INFO:Checking exceptions
2024-07-10 17:03:10,726:INFO:Preparing display monitor
2024-07-10 17:03:10,768:INFO:Initializing Linear Regression
2024-07-10 17:03:10,768:INFO:Total runtime is 0.0 minutes
2024-07-10 17:03:10,772:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:10,773:INFO:Initializing create_model()
2024-07-10 17:03:10,773:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:10,773:INFO:Checking exceptions
2024-07-10 17:03:10,773:INFO:Importing libraries
2024-07-10 17:03:10,773:INFO:Copying training dataset
2024-07-10 17:03:10,778:INFO:Defining folds
2024-07-10 17:03:10,779:INFO:Declaring metric variables
2024-07-10 17:03:10,782:INFO:Importing untrained model
2024-07-10 17:03:10,785:INFO:Linear Regression Imported successfully
2024-07-10 17:03:10,790:INFO:Starting cross validation
2024-07-10 17:03:10,800:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:14,103:INFO:Calculating mean and std
2024-07-10 17:03:14,105:INFO:Creating metrics dataframe
2024-07-10 17:03:14,108:INFO:Uploading results into container
2024-07-10 17:03:14,108:INFO:Uploading model into container now
2024-07-10 17:03:14,109:INFO:_master_model_container: 1
2024-07-10 17:03:14,109:INFO:_display_container: 2
2024-07-10 17:03:14,109:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2024-07-10 17:03:14,109:INFO:create_model() successfully completed......................................
2024-07-10 17:03:14,197:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:14,197:INFO:Creating metrics dataframe
2024-07-10 17:03:14,203:INFO:Initializing Lasso Regression
2024-07-10 17:03:14,203:INFO:Total runtime is 0.057265206178029375 minutes
2024-07-10 17:03:14,205:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:14,206:INFO:Initializing create_model()
2024-07-10 17:03:14,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:14,206:INFO:Checking exceptions
2024-07-10 17:03:14,206:INFO:Importing libraries
2024-07-10 17:03:14,206:INFO:Copying training dataset
2024-07-10 17:03:14,209:INFO:Defining folds
2024-07-10 17:03:14,210:INFO:Declaring metric variables
2024-07-10 17:03:14,212:INFO:Importing untrained model
2024-07-10 17:03:14,215:INFO:Lasso Regression Imported successfully
2024-07-10 17:03:14,223:INFO:Starting cross validation
2024-07-10 17:03:14,225:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:16,744:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.310e+16, tolerance: 1.205e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:16,751:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.825e+16, tolerance: 1.156e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:16,820:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.196e+16, tolerance: 1.202e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:16,825:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.657e+16, tolerance: 1.202e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:16,829:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.408e+16, tolerance: 1.210e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:16,836:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.058e+16, tolerance: 1.205e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:16,844:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+17, tolerance: 9.938e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:16,852:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.689e+16, tolerance: 7.605e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:16,852:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.064e+16, tolerance: 1.208e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:16,855:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.271e+16, tolerance: 1.205e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:16,899:INFO:Calculating mean and std
2024-07-10 17:03:16,901:INFO:Creating metrics dataframe
2024-07-10 17:03:16,903:INFO:Uploading results into container
2024-07-10 17:03:16,903:INFO:Uploading model into container now
2024-07-10 17:03:16,904:INFO:_master_model_container: 2
2024-07-10 17:03:16,904:INFO:_display_container: 2
2024-07-10 17:03:16,904:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2024-07-10 17:03:16,905:INFO:create_model() successfully completed......................................
2024-07-10 17:03:17,001:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:17,001:INFO:Creating metrics dataframe
2024-07-10 17:03:17,010:INFO:Initializing Ridge Regression
2024-07-10 17:03:17,010:INFO:Total runtime is 0.10404407183329265 minutes
2024-07-10 17:03:17,014:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:17,014:INFO:Initializing create_model()
2024-07-10 17:03:17,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:17,016:INFO:Checking exceptions
2024-07-10 17:03:17,016:INFO:Importing libraries
2024-07-10 17:03:17,016:INFO:Copying training dataset
2024-07-10 17:03:17,020:INFO:Defining folds
2024-07-10 17:03:17,021:INFO:Declaring metric variables
2024-07-10 17:03:17,023:INFO:Importing untrained model
2024-07-10 17:03:17,028:INFO:Ridge Regression Imported successfully
2024-07-10 17:03:17,034:INFO:Starting cross validation
2024-07-10 17:03:17,036:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:18,880:INFO:Calculating mean and std
2024-07-10 17:03:18,881:INFO:Creating metrics dataframe
2024-07-10 17:03:18,883:INFO:Uploading results into container
2024-07-10 17:03:18,884:INFO:Uploading model into container now
2024-07-10 17:03:18,885:INFO:_master_model_container: 3
2024-07-10 17:03:18,885:INFO:_display_container: 2
2024-07-10 17:03:18,886:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2024-07-10 17:03:18,886:INFO:create_model() successfully completed......................................
2024-07-10 17:03:18,971:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:18,971:INFO:Creating metrics dataframe
2024-07-10 17:03:18,980:INFO:Initializing Elastic Net
2024-07-10 17:03:18,980:INFO:Total runtime is 0.13687537113825482 minutes
2024-07-10 17:03:18,983:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:18,983:INFO:Initializing create_model()
2024-07-10 17:03:18,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:18,983:INFO:Checking exceptions
2024-07-10 17:03:18,983:INFO:Importing libraries
2024-07-10 17:03:18,983:INFO:Copying training dataset
2024-07-10 17:03:18,988:INFO:Defining folds
2024-07-10 17:03:18,988:INFO:Declaring metric variables
2024-07-10 17:03:18,990:INFO:Importing untrained model
2024-07-10 17:03:18,994:INFO:Elastic Net Imported successfully
2024-07-10 17:03:18,999:INFO:Starting cross validation
2024-07-10 17:03:19,001:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:19,148:INFO:Calculating mean and std
2024-07-10 17:03:19,149:INFO:Creating metrics dataframe
2024-07-10 17:03:19,150:INFO:Uploading results into container
2024-07-10 17:03:19,151:INFO:Uploading model into container now
2024-07-10 17:03:19,151:INFO:_master_model_container: 4
2024-07-10 17:03:19,151:INFO:_display_container: 2
2024-07-10 17:03:19,152:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2024-07-10 17:03:19,152:INFO:create_model() successfully completed......................................
2024-07-10 17:03:19,231:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:19,231:INFO:Creating metrics dataframe
2024-07-10 17:03:19,236:INFO:Initializing Least Angle Regression
2024-07-10 17:03:19,237:INFO:Total runtime is 0.14115969737370812 minutes
2024-07-10 17:03:19,241:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:19,241:INFO:Initializing create_model()
2024-07-10 17:03:19,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:19,241:INFO:Checking exceptions
2024-07-10 17:03:19,241:INFO:Importing libraries
2024-07-10 17:03:19,241:INFO:Copying training dataset
2024-07-10 17:03:19,245:INFO:Defining folds
2024-07-10 17:03:19,246:INFO:Declaring metric variables
2024-07-10 17:03:19,248:INFO:Importing untrained model
2024-07-10 17:03:19,250:INFO:Least Angle Regression Imported successfully
2024-07-10 17:03:19,259:INFO:Starting cross validation
2024-07-10 17:03:19,261:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:19,362:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.082e+05, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-10 17:03:19,363:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.937e+04, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-10 17:03:19,366:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.652e+04, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-10 17:03:19,368:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.686e+07, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-10 17:03:19,432:INFO:Calculating mean and std
2024-07-10 17:03:19,432:INFO:Creating metrics dataframe
2024-07-10 17:03:19,434:INFO:Uploading results into container
2024-07-10 17:03:19,435:INFO:Uploading model into container now
2024-07-10 17:03:19,435:INFO:_master_model_container: 5
2024-07-10 17:03:19,435:INFO:_display_container: 2
2024-07-10 17:03:19,436:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2024-07-10 17:03:19,436:INFO:create_model() successfully completed......................................
2024-07-10 17:03:19,520:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:19,520:INFO:Creating metrics dataframe
2024-07-10 17:03:19,527:INFO:Initializing Lasso Least Angle Regression
2024-07-10 17:03:19,528:INFO:Total runtime is 0.14600350856781008 minutes
2024-07-10 17:03:19,531:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:19,532:INFO:Initializing create_model()
2024-07-10 17:03:19,532:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:19,532:INFO:Checking exceptions
2024-07-10 17:03:19,532:INFO:Importing libraries
2024-07-10 17:03:19,532:INFO:Copying training dataset
2024-07-10 17:03:19,536:INFO:Defining folds
2024-07-10 17:03:19,536:INFO:Declaring metric variables
2024-07-10 17:03:19,538:INFO:Importing untrained model
2024-07-10 17:03:19,541:INFO:Lasso Least Angle Regression Imported successfully
2024-07-10 17:03:19,547:INFO:Starting cross validation
2024-07-10 17:03:19,550:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:19,644:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.082e+05, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-10 17:03:19,646:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.937e+04, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-10 17:03:19,648:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 53 iterations, alpha=9.546e+03, previous alpha=9.546e+03, with an active set of 44 regressors.
  warnings.warn(

2024-07-10 17:03:19,664:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 44 iterations, alpha=1.421e+04, previous alpha=1.408e+04, with an active set of 39 regressors.
  warnings.warn(

2024-07-10 17:03:19,712:INFO:Calculating mean and std
2024-07-10 17:03:19,712:INFO:Creating metrics dataframe
2024-07-10 17:03:19,714:INFO:Uploading results into container
2024-07-10 17:03:19,715:INFO:Uploading model into container now
2024-07-10 17:03:19,715:INFO:_master_model_container: 6
2024-07-10 17:03:19,715:INFO:_display_container: 2
2024-07-10 17:03:19,716:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2024-07-10 17:03:19,716:INFO:create_model() successfully completed......................................
2024-07-10 17:03:19,799:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:19,799:INFO:Creating metrics dataframe
2024-07-10 17:03:19,805:INFO:Initializing Orthogonal Matching Pursuit
2024-07-10 17:03:19,805:INFO:Total runtime is 0.15062181552251183 minutes
2024-07-10 17:03:19,808:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:19,808:INFO:Initializing create_model()
2024-07-10 17:03:19,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:19,808:INFO:Checking exceptions
2024-07-10 17:03:19,808:INFO:Importing libraries
2024-07-10 17:03:19,808:INFO:Copying training dataset
2024-07-10 17:03:19,812:INFO:Defining folds
2024-07-10 17:03:19,812:INFO:Declaring metric variables
2024-07-10 17:03:19,815:INFO:Importing untrained model
2024-07-10 17:03:19,817:INFO:Orthogonal Matching Pursuit Imported successfully
2024-07-10 17:03:19,823:INFO:Starting cross validation
2024-07-10 17:03:19,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:19,979:INFO:Calculating mean and std
2024-07-10 17:03:19,980:INFO:Creating metrics dataframe
2024-07-10 17:03:19,982:INFO:Uploading results into container
2024-07-10 17:03:19,982:INFO:Uploading model into container now
2024-07-10 17:03:19,983:INFO:_master_model_container: 7
2024-07-10 17:03:19,983:INFO:_display_container: 2
2024-07-10 17:03:19,983:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2024-07-10 17:03:19,983:INFO:create_model() successfully completed......................................
2024-07-10 17:03:20,068:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:20,068:INFO:Creating metrics dataframe
2024-07-10 17:03:20,074:INFO:Initializing Bayesian Ridge
2024-07-10 17:03:20,075:INFO:Total runtime is 0.15513208707173667 minutes
2024-07-10 17:03:20,077:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:20,078:INFO:Initializing create_model()
2024-07-10 17:03:20,078:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:20,078:INFO:Checking exceptions
2024-07-10 17:03:20,078:INFO:Importing libraries
2024-07-10 17:03:20,078:INFO:Copying training dataset
2024-07-10 17:03:20,083:INFO:Defining folds
2024-07-10 17:03:20,083:INFO:Declaring metric variables
2024-07-10 17:03:20,086:INFO:Importing untrained model
2024-07-10 17:03:20,089:INFO:Bayesian Ridge Imported successfully
2024-07-10 17:03:20,095:INFO:Starting cross validation
2024-07-10 17:03:20,098:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:20,263:INFO:Calculating mean and std
2024-07-10 17:03:20,263:INFO:Creating metrics dataframe
2024-07-10 17:03:20,265:INFO:Uploading results into container
2024-07-10 17:03:20,266:INFO:Uploading model into container now
2024-07-10 17:03:20,266:INFO:_master_model_container: 8
2024-07-10 17:03:20,266:INFO:_display_container: 2
2024-07-10 17:03:20,267:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2024-07-10 17:03:20,267:INFO:create_model() successfully completed......................................
2024-07-10 17:03:20,346:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:20,347:INFO:Creating metrics dataframe
2024-07-10 17:03:20,353:INFO:Initializing Passive Aggressive Regressor
2024-07-10 17:03:20,354:INFO:Total runtime is 0.15977083841959638 minutes
2024-07-10 17:03:20,357:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:20,358:INFO:Initializing create_model()
2024-07-10 17:03:20,358:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:20,358:INFO:Checking exceptions
2024-07-10 17:03:20,358:INFO:Importing libraries
2024-07-10 17:03:20,358:INFO:Copying training dataset
2024-07-10 17:03:20,363:INFO:Defining folds
2024-07-10 17:03:20,363:INFO:Declaring metric variables
2024-07-10 17:03:20,365:INFO:Importing untrained model
2024-07-10 17:03:20,369:INFO:Passive Aggressive Regressor Imported successfully
2024-07-10 17:03:20,375:INFO:Starting cross validation
2024-07-10 17:03:20,376:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:20,531:INFO:Calculating mean and std
2024-07-10 17:03:20,532:INFO:Creating metrics dataframe
2024-07-10 17:03:20,535:INFO:Uploading results into container
2024-07-10 17:03:20,536:INFO:Uploading model into container now
2024-07-10 17:03:20,536:INFO:_master_model_container: 9
2024-07-10 17:03:20,536:INFO:_display_container: 2
2024-07-10 17:03:20,537:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-10 17:03:20,537:INFO:create_model() successfully completed......................................
2024-07-10 17:03:20,616:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:20,616:INFO:Creating metrics dataframe
2024-07-10 17:03:20,622:INFO:Initializing Huber Regressor
2024-07-10 17:03:20,623:INFO:Total runtime is 0.16425225337346397 minutes
2024-07-10 17:03:20,625:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:20,626:INFO:Initializing create_model()
2024-07-10 17:03:20,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:20,626:INFO:Checking exceptions
2024-07-10 17:03:20,626:INFO:Importing libraries
2024-07-10 17:03:20,626:INFO:Copying training dataset
2024-07-10 17:03:20,632:INFO:Defining folds
2024-07-10 17:03:20,632:INFO:Declaring metric variables
2024-07-10 17:03:20,634:INFO:Importing untrained model
2024-07-10 17:03:20,638:INFO:Huber Regressor Imported successfully
2024-07-10 17:03:20,647:INFO:Starting cross validation
2024-07-10 17:03:20,651:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:20,777:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-10 17:03:20,796:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-10 17:03:20,826:INFO:Calculating mean and std
2024-07-10 17:03:20,827:INFO:Creating metrics dataframe
2024-07-10 17:03:20,829:INFO:Uploading results into container
2024-07-10 17:03:20,829:INFO:Uploading model into container now
2024-07-10 17:03:20,830:INFO:_master_model_container: 10
2024-07-10 17:03:20,830:INFO:_display_container: 2
2024-07-10 17:03:20,830:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2024-07-10 17:03:20,830:INFO:create_model() successfully completed......................................
2024-07-10 17:03:20,914:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:20,915:INFO:Creating metrics dataframe
2024-07-10 17:03:20,923:INFO:Initializing K Neighbors Regressor
2024-07-10 17:03:20,923:INFO:Total runtime is 0.16925151745478315 minutes
2024-07-10 17:03:20,925:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:20,925:INFO:Initializing create_model()
2024-07-10 17:03:20,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:20,925:INFO:Checking exceptions
2024-07-10 17:03:20,925:INFO:Importing libraries
2024-07-10 17:03:20,925:INFO:Copying training dataset
2024-07-10 17:03:20,930:INFO:Defining folds
2024-07-10 17:03:20,930:INFO:Declaring metric variables
2024-07-10 17:03:20,933:INFO:Importing untrained model
2024-07-10 17:03:20,935:INFO:K Neighbors Regressor Imported successfully
2024-07-10 17:03:20,945:INFO:Starting cross validation
2024-07-10 17:03:20,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:21,172:INFO:Calculating mean and std
2024-07-10 17:03:21,173:INFO:Creating metrics dataframe
2024-07-10 17:03:21,176:INFO:Uploading results into container
2024-07-10 17:03:21,177:INFO:Uploading model into container now
2024-07-10 17:03:21,177:INFO:_master_model_container: 11
2024-07-10 17:03:21,177:INFO:_display_container: 2
2024-07-10 17:03:21,177:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2024-07-10 17:03:21,177:INFO:create_model() successfully completed......................................
2024-07-10 17:03:21,259:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:21,259:INFO:Creating metrics dataframe
2024-07-10 17:03:21,270:INFO:Initializing Decision Tree Regressor
2024-07-10 17:03:21,270:INFO:Total runtime is 0.17504414717356367 minutes
2024-07-10 17:03:21,273:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:21,273:INFO:Initializing create_model()
2024-07-10 17:03:21,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:21,274:INFO:Checking exceptions
2024-07-10 17:03:21,274:INFO:Importing libraries
2024-07-10 17:03:21,274:INFO:Copying training dataset
2024-07-10 17:03:21,278:INFO:Defining folds
2024-07-10 17:03:21,278:INFO:Declaring metric variables
2024-07-10 17:03:21,281:INFO:Importing untrained model
2024-07-10 17:03:21,285:INFO:Decision Tree Regressor Imported successfully
2024-07-10 17:03:21,292:INFO:Starting cross validation
2024-07-10 17:03:21,295:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:21,452:INFO:Calculating mean and std
2024-07-10 17:03:21,453:INFO:Creating metrics dataframe
2024-07-10 17:03:21,455:INFO:Uploading results into container
2024-07-10 17:03:21,456:INFO:Uploading model into container now
2024-07-10 17:03:21,456:INFO:_master_model_container: 12
2024-07-10 17:03:21,456:INFO:_display_container: 2
2024-07-10 17:03:21,456:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2024-07-10 17:03:21,456:INFO:create_model() successfully completed......................................
2024-07-10 17:03:21,534:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:21,535:INFO:Creating metrics dataframe
2024-07-10 17:03:21,545:INFO:Initializing Random Forest Regressor
2024-07-10 17:03:21,545:INFO:Total runtime is 0.17962272564570111 minutes
2024-07-10 17:03:21,548:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:21,548:INFO:Initializing create_model()
2024-07-10 17:03:21,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:21,548:INFO:Checking exceptions
2024-07-10 17:03:21,549:INFO:Importing libraries
2024-07-10 17:03:21,549:INFO:Copying training dataset
2024-07-10 17:03:21,552:INFO:Defining folds
2024-07-10 17:03:21,552:INFO:Declaring metric variables
2024-07-10 17:03:21,554:INFO:Importing untrained model
2024-07-10 17:03:21,556:INFO:Random Forest Regressor Imported successfully
2024-07-10 17:03:21,562:INFO:Starting cross validation
2024-07-10 17:03:21,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:22,155:INFO:Calculating mean and std
2024-07-10 17:03:22,156:INFO:Creating metrics dataframe
2024-07-10 17:03:22,159:INFO:Uploading results into container
2024-07-10 17:03:22,159:INFO:Uploading model into container now
2024-07-10 17:03:22,160:INFO:_master_model_container: 13
2024-07-10 17:03:22,160:INFO:_display_container: 2
2024-07-10 17:03:22,160:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2024-07-10 17:03:22,160:INFO:create_model() successfully completed......................................
2024-07-10 17:03:22,239:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:22,239:INFO:Creating metrics dataframe
2024-07-10 17:03:22,247:INFO:Initializing Extra Trees Regressor
2024-07-10 17:03:22,247:INFO:Total runtime is 0.19132522741953534 minutes
2024-07-10 17:03:22,251:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:22,251:INFO:Initializing create_model()
2024-07-10 17:03:22,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:22,251:INFO:Checking exceptions
2024-07-10 17:03:22,251:INFO:Importing libraries
2024-07-10 17:03:22,252:INFO:Copying training dataset
2024-07-10 17:03:22,256:INFO:Defining folds
2024-07-10 17:03:22,256:INFO:Declaring metric variables
2024-07-10 17:03:22,259:INFO:Importing untrained model
2024-07-10 17:03:22,262:INFO:Extra Trees Regressor Imported successfully
2024-07-10 17:03:22,269:INFO:Starting cross validation
2024-07-10 17:03:22,272:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:22,830:INFO:Calculating mean and std
2024-07-10 17:03:22,830:INFO:Creating metrics dataframe
2024-07-10 17:03:22,832:INFO:Uploading results into container
2024-07-10 17:03:22,833:INFO:Uploading model into container now
2024-07-10 17:03:22,833:INFO:_master_model_container: 14
2024-07-10 17:03:22,834:INFO:_display_container: 2
2024-07-10 17:03:22,834:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2024-07-10 17:03:22,834:INFO:create_model() successfully completed......................................
2024-07-10 17:03:22,916:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:22,916:INFO:Creating metrics dataframe
2024-07-10 17:03:22,924:INFO:Initializing AdaBoost Regressor
2024-07-10 17:03:22,924:INFO:Total runtime is 0.2026092330614726 minutes
2024-07-10 17:03:22,927:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:22,927:INFO:Initializing create_model()
2024-07-10 17:03:22,927:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:22,927:INFO:Checking exceptions
2024-07-10 17:03:22,927:INFO:Importing libraries
2024-07-10 17:03:22,927:INFO:Copying training dataset
2024-07-10 17:03:22,933:INFO:Defining folds
2024-07-10 17:03:22,933:INFO:Declaring metric variables
2024-07-10 17:03:22,936:INFO:Importing untrained model
2024-07-10 17:03:22,940:INFO:AdaBoost Regressor Imported successfully
2024-07-10 17:03:22,950:INFO:Starting cross validation
2024-07-10 17:03:22,952:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:23,235:INFO:Calculating mean and std
2024-07-10 17:03:23,235:INFO:Creating metrics dataframe
2024-07-10 17:03:23,237:INFO:Uploading results into container
2024-07-10 17:03:23,238:INFO:Uploading model into container now
2024-07-10 17:03:23,238:INFO:_master_model_container: 15
2024-07-10 17:03:23,238:INFO:_display_container: 2
2024-07-10 17:03:23,238:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2024-07-10 17:03:23,239:INFO:create_model() successfully completed......................................
2024-07-10 17:03:23,317:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:23,318:INFO:Creating metrics dataframe
2024-07-10 17:03:23,326:INFO:Initializing Gradient Boosting Regressor
2024-07-10 17:03:23,326:INFO:Total runtime is 0.2093037327130636 minutes
2024-07-10 17:03:23,331:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:23,331:INFO:Initializing create_model()
2024-07-10 17:03:23,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:23,332:INFO:Checking exceptions
2024-07-10 17:03:23,332:INFO:Importing libraries
2024-07-10 17:03:23,332:INFO:Copying training dataset
2024-07-10 17:03:23,338:INFO:Defining folds
2024-07-10 17:03:23,338:INFO:Declaring metric variables
2024-07-10 17:03:23,340:INFO:Importing untrained model
2024-07-10 17:03:23,343:INFO:Gradient Boosting Regressor Imported successfully
2024-07-10 17:03:23,349:INFO:Starting cross validation
2024-07-10 17:03:23,352:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:23,672:INFO:Calculating mean and std
2024-07-10 17:03:23,672:INFO:Creating metrics dataframe
2024-07-10 17:03:23,674:INFO:Uploading results into container
2024-07-10 17:03:23,675:INFO:Uploading model into container now
2024-07-10 17:03:23,675:INFO:_master_model_container: 16
2024-07-10 17:03:23,675:INFO:_display_container: 2
2024-07-10 17:03:23,676:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-10 17:03:23,676:INFO:create_model() successfully completed......................................
2024-07-10 17:03:23,754:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:23,755:INFO:Creating metrics dataframe
2024-07-10 17:03:23,762:INFO:Initializing Extreme Gradient Boosting
2024-07-10 17:03:23,763:INFO:Total runtime is 0.21659280459086105 minutes
2024-07-10 17:03:23,766:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:23,766:INFO:Initializing create_model()
2024-07-10 17:03:23,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:23,766:INFO:Checking exceptions
2024-07-10 17:03:23,766:INFO:Importing libraries
2024-07-10 17:03:23,766:INFO:Copying training dataset
2024-07-10 17:03:23,770:INFO:Defining folds
2024-07-10 17:03:23,770:INFO:Declaring metric variables
2024-07-10 17:03:23,773:INFO:Importing untrained model
2024-07-10 17:03:23,775:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 17:03:23,783:INFO:Starting cross validation
2024-07-10 17:03:23,788:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:24,716:INFO:Calculating mean and std
2024-07-10 17:03:24,716:INFO:Creating metrics dataframe
2024-07-10 17:03:24,718:INFO:Uploading results into container
2024-07-10 17:03:24,718:INFO:Uploading model into container now
2024-07-10 17:03:24,719:INFO:_master_model_container: 17
2024-07-10 17:03:24,719:INFO:_display_container: 2
2024-07-10 17:03:24,721:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:03:24,721:INFO:create_model() successfully completed......................................
2024-07-10 17:03:24,800:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:24,800:INFO:Creating metrics dataframe
2024-07-10 17:03:24,807:INFO:Initializing Light Gradient Boosting Machine
2024-07-10 17:03:24,808:INFO:Total runtime is 0.2340040763219198 minutes
2024-07-10 17:03:24,812:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:24,812:INFO:Initializing create_model()
2024-07-10 17:03:24,812:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:24,813:INFO:Checking exceptions
2024-07-10 17:03:24,813:INFO:Importing libraries
2024-07-10 17:03:24,813:INFO:Copying training dataset
2024-07-10 17:03:24,817:INFO:Defining folds
2024-07-10 17:03:24,817:INFO:Declaring metric variables
2024-07-10 17:03:24,820:INFO:Importing untrained model
2024-07-10 17:03:24,822:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-10 17:03:24,829:INFO:Starting cross validation
2024-07-10 17:03:24,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:26,562:INFO:Calculating mean and std
2024-07-10 17:03:26,563:INFO:Creating metrics dataframe
2024-07-10 17:03:26,566:INFO:Uploading results into container
2024-07-10 17:03:26,567:INFO:Uploading model into container now
2024-07-10 17:03:26,567:INFO:_master_model_container: 18
2024-07-10 17:03:26,567:INFO:_display_container: 2
2024-07-10 17:03:26,568:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2024-07-10 17:03:26,568:INFO:create_model() successfully completed......................................
2024-07-10 17:03:26,674:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:26,675:INFO:Creating metrics dataframe
2024-07-10 17:03:26,682:INFO:Initializing Dummy Regressor
2024-07-10 17:03:26,682:INFO:Total runtime is 0.26524342298507697 minutes
2024-07-10 17:03:26,685:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:26,685:INFO:Initializing create_model()
2024-07-10 17:03:26,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7D8F9D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:26,686:INFO:Checking exceptions
2024-07-10 17:03:26,686:INFO:Importing libraries
2024-07-10 17:03:26,686:INFO:Copying training dataset
2024-07-10 17:03:26,690:INFO:Defining folds
2024-07-10 17:03:26,690:INFO:Declaring metric variables
2024-07-10 17:03:26,692:INFO:Importing untrained model
2024-07-10 17:03:26,695:INFO:Dummy Regressor Imported successfully
2024-07-10 17:03:26,701:INFO:Starting cross validation
2024-07-10 17:03:26,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:26,840:INFO:Calculating mean and std
2024-07-10 17:03:26,842:INFO:Creating metrics dataframe
2024-07-10 17:03:26,843:INFO:Uploading results into container
2024-07-10 17:03:26,844:INFO:Uploading model into container now
2024-07-10 17:03:26,844:INFO:_master_model_container: 19
2024-07-10 17:03:26,844:INFO:_display_container: 2
2024-07-10 17:03:26,844:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2024-07-10 17:03:26,844:INFO:create_model() successfully completed......................................
2024-07-10 17:03:26,928:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:26,928:INFO:Creating metrics dataframe
2024-07-10 17:03:26,943:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-07-10 17:03:26,951:INFO:Initializing create_model()
2024-07-10 17:03:26,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:26,951:INFO:Checking exceptions
2024-07-10 17:03:26,953:INFO:Importing libraries
2024-07-10 17:03:26,953:INFO:Copying training dataset
2024-07-10 17:03:26,956:INFO:Defining folds
2024-07-10 17:03:26,956:INFO:Declaring metric variables
2024-07-10 17:03:26,956:INFO:Importing untrained model
2024-07-10 17:03:26,956:INFO:Declaring custom model
2024-07-10 17:03:26,957:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 17:03:26,958:INFO:Cross validation set to False
2024-07-10 17:03:26,958:INFO:Fitting Model
2024-07-10 17:03:27,358:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:03:27,359:INFO:create_model() successfully completed......................................
2024-07-10 17:03:27,488:INFO:_master_model_container: 19
2024-07-10 17:03:27,488:INFO:_display_container: 2
2024-07-10 17:03:27,489:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:03:27,489:INFO:compare_models() successfully completed......................................
2024-07-10 17:03:27,490:INFO:Initializing create_model()
2024-07-10 17:03:27,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:27,491:INFO:Checking exceptions
2024-07-10 17:03:27,508:INFO:Importing libraries
2024-07-10 17:03:27,508:INFO:Copying training dataset
2024-07-10 17:03:27,512:INFO:Defining folds
2024-07-10 17:03:27,512:INFO:Declaring metric variables
2024-07-10 17:03:27,515:INFO:Importing untrained model
2024-07-10 17:03:27,515:INFO:Declaring custom model
2024-07-10 17:03:27,518:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 17:03:27,524:INFO:Starting cross validation
2024-07-10 17:03:27,527:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:28,303:INFO:Calculating mean and std
2024-07-10 17:03:28,303:INFO:Creating metrics dataframe
2024-07-10 17:03:28,307:INFO:Finalizing model
2024-07-10 17:03:28,491:INFO:Uploading results into container
2024-07-10 17:03:28,492:INFO:Uploading model into container now
2024-07-10 17:03:28,500:INFO:_master_model_container: 20
2024-07-10 17:03:28,500:INFO:_display_container: 3
2024-07-10 17:03:28,501:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:03:28,501:INFO:create_model() successfully completed......................................
2024-07-10 17:03:28,590:INFO:Initializing tune_model()
2024-07-10 17:03:28,590:INFO:tune_model(estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>)
2024-07-10 17:03:28,590:INFO:Checking exceptions
2024-07-10 17:03:28,602:INFO:Copying training dataset
2024-07-10 17:03:28,605:INFO:Checking base model
2024-07-10 17:03:28,606:INFO:Base model : Extreme Gradient Boosting
2024-07-10 17:03:28,608:INFO:Declaring metric variables
2024-07-10 17:03:28,610:INFO:Defining Hyperparameters
2024-07-10 17:03:28,697:INFO:Tuning with n_jobs=-1
2024-07-10 17:03:28,697:INFO:Initializing RandomizedSearchCV
2024-07-10 17:03:30,889:INFO:best_params: {'actual_estimator__subsample': 0.2, 'actual_estimator__scale_pos_weight': 37.7, 'actual_estimator__reg_lambda': 0.2, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__n_estimators': 220, 'actual_estimator__min_child_weight': 4, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.9}
2024-07-10 17:03:30,890:INFO:Hyperparameter search completed
2024-07-10 17:03:30,890:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:30,891:INFO:Initializing create_model()
2024-07-10 17:03:30,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7CFE98A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.2, 'scale_pos_weight': 37.7, 'reg_lambda': 0.2, 'reg_alpha': 0.0001, 'n_estimators': 220, 'min_child_weight': 4, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bytree': 0.9})
2024-07-10 17:03:30,891:INFO:Checking exceptions
2024-07-10 17:03:30,891:INFO:Importing libraries
2024-07-10 17:03:30,892:INFO:Copying training dataset
2024-07-10 17:03:30,896:INFO:Defining folds
2024-07-10 17:03:30,896:INFO:Declaring metric variables
2024-07-10 17:03:30,899:INFO:Importing untrained model
2024-07-10 17:03:30,900:INFO:Declaring custom model
2024-07-10 17:03:30,903:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 17:03:30,907:INFO:Starting cross validation
2024-07-10 17:03:30,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:31,278:INFO:Calculating mean and std
2024-07-10 17:03:31,279:INFO:Creating metrics dataframe
2024-07-10 17:03:31,283:INFO:Finalizing model
2024-07-10 17:03:31,704:INFO:Uploading results into container
2024-07-10 17:03:31,704:INFO:Uploading model into container now
2024-07-10 17:03:31,705:INFO:_master_model_container: 21
2024-07-10 17:03:31,705:INFO:_display_container: 4
2024-07-10 17:03:31,706:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.05, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=10, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=220, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:03:31,706:INFO:create_model() successfully completed......................................
2024-07-10 17:03:31,814:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:31,814:INFO:choose_better activated
2024-07-10 17:03:31,817:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:31,818:INFO:Initializing create_model()
2024-07-10 17:03:31,818:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:31,819:INFO:Checking exceptions
2024-07-10 17:03:31,820:INFO:Importing libraries
2024-07-10 17:03:31,820:INFO:Copying training dataset
2024-07-10 17:03:31,823:INFO:Defining folds
2024-07-10 17:03:31,824:INFO:Declaring metric variables
2024-07-10 17:03:31,824:INFO:Importing untrained model
2024-07-10 17:03:31,824:INFO:Declaring custom model
2024-07-10 17:03:31,824:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 17:03:31,824:INFO:Starting cross validation
2024-07-10 17:03:31,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:32,085:INFO:Calculating mean and std
2024-07-10 17:03:32,085:INFO:Creating metrics dataframe
2024-07-10 17:03:32,087:INFO:Finalizing model
2024-07-10 17:03:32,266:INFO:Uploading results into container
2024-07-10 17:03:32,267:INFO:Uploading model into container now
2024-07-10 17:03:32,267:INFO:_master_model_container: 22
2024-07-10 17:03:32,267:INFO:_display_container: 5
2024-07-10 17:03:32,268:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:03:32,268:INFO:create_model() successfully completed......................................
2024-07-10 17:03:32,385:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:32,386:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...) result for R2 is 0.7553
2024-07-10 17:03:32,386:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.05, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=10, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=220, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...) result for R2 is 0.7289
2024-07-10 17:03:32,387:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...) is best model
2024-07-10 17:03:32,387:INFO:choose_better completed
2024-07-10 17:03:32,387:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-10 17:03:32,394:INFO:_master_model_container: 22
2024-07-10 17:03:32,394:INFO:_display_container: 4
2024-07-10 17:03:32,394:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:03:32,395:INFO:tune_model() successfully completed......................................
2024-07-10 17:03:32,476:INFO:Initializing predict_model()
2024-07-10 17:03:32,476:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014A7D273A30>)
2024-07-10 17:03:32,476:INFO:Checking exceptions
2024-07-10 17:03:32,477:INFO:Preloading libraries
2024-07-10 17:03:32,618:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-07-10 17:03:51,085:INFO:Initializing compare_models()
2024-07-10 17:03:51,086:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-07-10 17:03:51,086:INFO:Checking exceptions
2024-07-10 17:03:51,088:INFO:Preparing display monitor
2024-07-10 17:03:51,108:INFO:Initializing Linear Regression
2024-07-10 17:03:51,109:INFO:Total runtime is 2.0984808603922526e-05 minutes
2024-07-10 17:03:51,112:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:51,112:INFO:Initializing create_model()
2024-07-10 17:03:51,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:51,112:INFO:Checking exceptions
2024-07-10 17:03:51,113:INFO:Importing libraries
2024-07-10 17:03:51,113:INFO:Copying training dataset
2024-07-10 17:03:51,119:INFO:Defining folds
2024-07-10 17:03:51,119:INFO:Declaring metric variables
2024-07-10 17:03:51,122:INFO:Importing untrained model
2024-07-10 17:03:51,124:INFO:Linear Regression Imported successfully
2024-07-10 17:03:51,130:INFO:Starting cross validation
2024-07-10 17:03:51,133:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:51,283:INFO:Calculating mean and std
2024-07-10 17:03:51,283:INFO:Creating metrics dataframe
2024-07-10 17:03:51,285:INFO:Uploading results into container
2024-07-10 17:03:51,285:INFO:Uploading model into container now
2024-07-10 17:03:51,286:INFO:_master_model_container: 23
2024-07-10 17:03:51,286:INFO:_display_container: 6
2024-07-10 17:03:51,286:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2024-07-10 17:03:51,286:INFO:create_model() successfully completed......................................
2024-07-10 17:03:51,368:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:51,369:INFO:Creating metrics dataframe
2024-07-10 17:03:51,373:INFO:Initializing Lasso Regression
2024-07-10 17:03:51,373:INFO:Total runtime is 0.004417053858439128 minutes
2024-07-10 17:03:51,377:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:51,377:INFO:Initializing create_model()
2024-07-10 17:03:51,377:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:51,377:INFO:Checking exceptions
2024-07-10 17:03:51,377:INFO:Importing libraries
2024-07-10 17:03:51,377:INFO:Copying training dataset
2024-07-10 17:03:51,382:INFO:Defining folds
2024-07-10 17:03:51,382:INFO:Declaring metric variables
2024-07-10 17:03:51,384:INFO:Importing untrained model
2024-07-10 17:03:51,387:INFO:Lasso Regression Imported successfully
2024-07-10 17:03:51,392:INFO:Starting cross validation
2024-07-10 17:03:51,395:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:51,490:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.825e+16, tolerance: 1.156e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:51,508:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.310e+16, tolerance: 1.205e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:51,508:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.196e+16, tolerance: 1.202e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:51,517:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.657e+16, tolerance: 1.202e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:51,518:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.689e+16, tolerance: 7.605e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:51,525:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.064e+16, tolerance: 1.208e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:51,532:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.408e+16, tolerance: 1.210e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:51,537:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.058e+16, tolerance: 1.205e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:51,542:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.271e+16, tolerance: 1.205e+14
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:51,554:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+17, tolerance: 9.938e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 17:03:51,585:INFO:Calculating mean and std
2024-07-10 17:03:51,586:INFO:Creating metrics dataframe
2024-07-10 17:03:51,589:INFO:Uploading results into container
2024-07-10 17:03:51,589:INFO:Uploading model into container now
2024-07-10 17:03:51,590:INFO:_master_model_container: 24
2024-07-10 17:03:51,590:INFO:_display_container: 6
2024-07-10 17:03:51,590:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2024-07-10 17:03:51,590:INFO:create_model() successfully completed......................................
2024-07-10 17:03:51,675:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:51,675:INFO:Creating metrics dataframe
2024-07-10 17:03:51,681:INFO:Initializing Ridge Regression
2024-07-10 17:03:51,682:INFO:Total runtime is 0.0095756729443868 minutes
2024-07-10 17:03:51,685:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:51,685:INFO:Initializing create_model()
2024-07-10 17:03:51,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:51,686:INFO:Checking exceptions
2024-07-10 17:03:51,686:INFO:Importing libraries
2024-07-10 17:03:51,686:INFO:Copying training dataset
2024-07-10 17:03:51,690:INFO:Defining folds
2024-07-10 17:03:51,690:INFO:Declaring metric variables
2024-07-10 17:03:51,692:INFO:Importing untrained model
2024-07-10 17:03:51,694:INFO:Ridge Regression Imported successfully
2024-07-10 17:03:51,701:INFO:Starting cross validation
2024-07-10 17:03:51,703:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:51,854:INFO:Calculating mean and std
2024-07-10 17:03:51,854:INFO:Creating metrics dataframe
2024-07-10 17:03:51,856:INFO:Uploading results into container
2024-07-10 17:03:51,856:INFO:Uploading model into container now
2024-07-10 17:03:51,856:INFO:_master_model_container: 25
2024-07-10 17:03:51,856:INFO:_display_container: 6
2024-07-10 17:03:51,856:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2024-07-10 17:03:51,856:INFO:create_model() successfully completed......................................
2024-07-10 17:03:51,936:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:51,937:INFO:Creating metrics dataframe
2024-07-10 17:03:51,942:INFO:Initializing Elastic Net
2024-07-10 17:03:51,942:INFO:Total runtime is 0.013904702663421632 minutes
2024-07-10 17:03:51,946:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:51,946:INFO:Initializing create_model()
2024-07-10 17:03:51,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:51,946:INFO:Checking exceptions
2024-07-10 17:03:51,946:INFO:Importing libraries
2024-07-10 17:03:51,947:INFO:Copying training dataset
2024-07-10 17:03:51,950:INFO:Defining folds
2024-07-10 17:03:51,950:INFO:Declaring metric variables
2024-07-10 17:03:51,953:INFO:Importing untrained model
2024-07-10 17:03:51,955:INFO:Elastic Net Imported successfully
2024-07-10 17:03:51,960:INFO:Starting cross validation
2024-07-10 17:03:51,962:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:52,117:INFO:Calculating mean and std
2024-07-10 17:03:52,118:INFO:Creating metrics dataframe
2024-07-10 17:03:52,119:INFO:Uploading results into container
2024-07-10 17:03:52,120:INFO:Uploading model into container now
2024-07-10 17:03:52,120:INFO:_master_model_container: 26
2024-07-10 17:03:52,120:INFO:_display_container: 6
2024-07-10 17:03:52,120:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2024-07-10 17:03:52,121:INFO:create_model() successfully completed......................................
2024-07-10 17:03:52,201:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:52,201:INFO:Creating metrics dataframe
2024-07-10 17:03:52,206:INFO:Initializing Least Angle Regression
2024-07-10 17:03:52,207:INFO:Total runtime is 0.018324605623881024 minutes
2024-07-10 17:03:52,210:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:52,210:INFO:Initializing create_model()
2024-07-10 17:03:52,211:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:52,211:INFO:Checking exceptions
2024-07-10 17:03:52,211:INFO:Importing libraries
2024-07-10 17:03:52,212:INFO:Copying training dataset
2024-07-10 17:03:52,218:INFO:Defining folds
2024-07-10 17:03:52,218:INFO:Declaring metric variables
2024-07-10 17:03:52,221:INFO:Importing untrained model
2024-07-10 17:03:52,224:INFO:Least Angle Regression Imported successfully
2024-07-10 17:03:52,230:INFO:Starting cross validation
2024-07-10 17:03:52,232:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:52,323:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.082e+05, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-10 17:03:52,324:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.937e+04, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-10 17:03:52,327:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.652e+04, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-10 17:03:52,329:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=2.686e+07, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-10 17:03:52,402:INFO:Calculating mean and std
2024-07-10 17:03:52,403:INFO:Creating metrics dataframe
2024-07-10 17:03:52,405:INFO:Uploading results into container
2024-07-10 17:03:52,405:INFO:Uploading model into container now
2024-07-10 17:03:52,406:INFO:_master_model_container: 27
2024-07-10 17:03:52,406:INFO:_display_container: 6
2024-07-10 17:03:52,406:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2024-07-10 17:03:52,406:INFO:create_model() successfully completed......................................
2024-07-10 17:03:52,483:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:52,483:INFO:Creating metrics dataframe
2024-07-10 17:03:52,489:INFO:Initializing Lasso Least Angle Regression
2024-07-10 17:03:52,489:INFO:Total runtime is 0.02302902142206828 minutes
2024-07-10 17:03:52,492:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:52,492:INFO:Initializing create_model()
2024-07-10 17:03:52,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:52,492:INFO:Checking exceptions
2024-07-10 17:03:52,493:INFO:Importing libraries
2024-07-10 17:03:52,493:INFO:Copying training dataset
2024-07-10 17:03:52,498:INFO:Defining folds
2024-07-10 17:03:52,499:INFO:Declaring metric variables
2024-07-10 17:03:52,501:INFO:Importing untrained model
2024-07-10 17:03:52,503:INFO:Lasso Least Angle Regression Imported successfully
2024-07-10 17:03:52,512:INFO:Starting cross validation
2024-07-10 17:03:52,514:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:52,595:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.082e+05, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-10 17:03:52,597:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.937e+04, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-10 17:03:52,600:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 53 iterations, alpha=9.546e+03, previous alpha=9.546e+03, with an active set of 44 regressors.
  warnings.warn(

2024-07-10 17:03:52,621:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 44 iterations, alpha=1.421e+04, previous alpha=1.408e+04, with an active set of 39 regressors.
  warnings.warn(

2024-07-10 17:03:52,671:INFO:Calculating mean and std
2024-07-10 17:03:52,671:INFO:Creating metrics dataframe
2024-07-10 17:03:52,673:INFO:Uploading results into container
2024-07-10 17:03:52,673:INFO:Uploading model into container now
2024-07-10 17:03:52,673:INFO:_master_model_container: 28
2024-07-10 17:03:52,673:INFO:_display_container: 6
2024-07-10 17:03:52,674:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2024-07-10 17:03:52,674:INFO:create_model() successfully completed......................................
2024-07-10 17:03:52,752:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:52,752:INFO:Creating metrics dataframe
2024-07-10 17:03:52,758:INFO:Initializing Orthogonal Matching Pursuit
2024-07-10 17:03:52,758:INFO:Total runtime is 0.0275005578994751 minutes
2024-07-10 17:03:52,761:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:52,761:INFO:Initializing create_model()
2024-07-10 17:03:52,761:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:52,762:INFO:Checking exceptions
2024-07-10 17:03:52,762:INFO:Importing libraries
2024-07-10 17:03:52,762:INFO:Copying training dataset
2024-07-10 17:03:52,768:INFO:Defining folds
2024-07-10 17:03:52,768:INFO:Declaring metric variables
2024-07-10 17:03:52,771:INFO:Importing untrained model
2024-07-10 17:03:52,773:INFO:Orthogonal Matching Pursuit Imported successfully
2024-07-10 17:03:52,779:INFO:Starting cross validation
2024-07-10 17:03:52,780:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:52,941:INFO:Calculating mean and std
2024-07-10 17:03:52,942:INFO:Creating metrics dataframe
2024-07-10 17:03:52,944:INFO:Uploading results into container
2024-07-10 17:03:52,944:INFO:Uploading model into container now
2024-07-10 17:03:52,945:INFO:_master_model_container: 29
2024-07-10 17:03:52,945:INFO:_display_container: 6
2024-07-10 17:03:52,945:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2024-07-10 17:03:52,945:INFO:create_model() successfully completed......................................
2024-07-10 17:03:53,023:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:53,024:INFO:Creating metrics dataframe
2024-07-10 17:03:53,032:INFO:Initializing Bayesian Ridge
2024-07-10 17:03:53,033:INFO:Total runtime is 0.03209598064422608 minutes
2024-07-10 17:03:53,036:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:53,037:INFO:Initializing create_model()
2024-07-10 17:03:53,037:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:53,037:INFO:Checking exceptions
2024-07-10 17:03:53,037:INFO:Importing libraries
2024-07-10 17:03:53,037:INFO:Copying training dataset
2024-07-10 17:03:53,042:INFO:Defining folds
2024-07-10 17:03:53,042:INFO:Declaring metric variables
2024-07-10 17:03:53,045:INFO:Importing untrained model
2024-07-10 17:03:53,048:INFO:Bayesian Ridge Imported successfully
2024-07-10 17:03:53,053:INFO:Starting cross validation
2024-07-10 17:03:53,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:53,209:INFO:Calculating mean and std
2024-07-10 17:03:53,210:INFO:Creating metrics dataframe
2024-07-10 17:03:53,212:INFO:Uploading results into container
2024-07-10 17:03:53,212:INFO:Uploading model into container now
2024-07-10 17:03:53,212:INFO:_master_model_container: 30
2024-07-10 17:03:53,212:INFO:_display_container: 6
2024-07-10 17:03:53,213:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2024-07-10 17:03:53,213:INFO:create_model() successfully completed......................................
2024-07-10 17:03:53,294:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:53,295:INFO:Creating metrics dataframe
2024-07-10 17:03:53,303:INFO:Initializing Passive Aggressive Regressor
2024-07-10 17:03:53,303:INFO:Total runtime is 0.03658713499704997 minutes
2024-07-10 17:03:53,305:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:53,306:INFO:Initializing create_model()
2024-07-10 17:03:53,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:53,306:INFO:Checking exceptions
2024-07-10 17:03:53,306:INFO:Importing libraries
2024-07-10 17:03:53,306:INFO:Copying training dataset
2024-07-10 17:03:53,311:INFO:Defining folds
2024-07-10 17:03:53,311:INFO:Declaring metric variables
2024-07-10 17:03:53,315:INFO:Importing untrained model
2024-07-10 17:03:53,319:INFO:Passive Aggressive Regressor Imported successfully
2024-07-10 17:03:53,323:INFO:Starting cross validation
2024-07-10 17:03:53,325:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:53,492:INFO:Calculating mean and std
2024-07-10 17:03:53,493:INFO:Creating metrics dataframe
2024-07-10 17:03:53,495:INFO:Uploading results into container
2024-07-10 17:03:53,495:INFO:Uploading model into container now
2024-07-10 17:03:53,496:INFO:_master_model_container: 31
2024-07-10 17:03:53,496:INFO:_display_container: 6
2024-07-10 17:03:53,496:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-10 17:03:53,496:INFO:create_model() successfully completed......................................
2024-07-10 17:03:53,575:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:53,575:INFO:Creating metrics dataframe
2024-07-10 17:03:53,582:INFO:Initializing Huber Regressor
2024-07-10 17:03:53,582:INFO:Total runtime is 0.04122997124989828 minutes
2024-07-10 17:03:53,585:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:53,586:INFO:Initializing create_model()
2024-07-10 17:03:53,586:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:53,586:INFO:Checking exceptions
2024-07-10 17:03:53,586:INFO:Importing libraries
2024-07-10 17:03:53,586:INFO:Copying training dataset
2024-07-10 17:03:53,590:INFO:Defining folds
2024-07-10 17:03:53,590:INFO:Declaring metric variables
2024-07-10 17:03:53,592:INFO:Importing untrained model
2024-07-10 17:03:53,594:INFO:Huber Regressor Imported successfully
2024-07-10 17:03:53,603:INFO:Starting cross validation
2024-07-10 17:03:53,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:53,725:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-10 17:03:53,739:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-10 17:03:53,772:INFO:Calculating mean and std
2024-07-10 17:03:53,772:INFO:Creating metrics dataframe
2024-07-10 17:03:53,774:INFO:Uploading results into container
2024-07-10 17:03:53,775:INFO:Uploading model into container now
2024-07-10 17:03:53,776:INFO:_master_model_container: 32
2024-07-10 17:03:53,776:INFO:_display_container: 6
2024-07-10 17:03:53,776:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2024-07-10 17:03:53,776:INFO:create_model() successfully completed......................................
2024-07-10 17:03:53,855:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:53,856:INFO:Creating metrics dataframe
2024-07-10 17:03:53,862:INFO:Initializing K Neighbors Regressor
2024-07-10 17:03:53,862:INFO:Total runtime is 0.045897456010182705 minutes
2024-07-10 17:03:53,864:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:53,865:INFO:Initializing create_model()
2024-07-10 17:03:53,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:53,865:INFO:Checking exceptions
2024-07-10 17:03:53,866:INFO:Importing libraries
2024-07-10 17:03:53,866:INFO:Copying training dataset
2024-07-10 17:03:53,871:INFO:Defining folds
2024-07-10 17:03:53,871:INFO:Declaring metric variables
2024-07-10 17:03:53,874:INFO:Importing untrained model
2024-07-10 17:03:53,876:INFO:K Neighbors Regressor Imported successfully
2024-07-10 17:03:53,886:INFO:Starting cross validation
2024-07-10 17:03:53,888:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:54,087:INFO:Calculating mean and std
2024-07-10 17:03:54,087:INFO:Creating metrics dataframe
2024-07-10 17:03:54,089:INFO:Uploading results into container
2024-07-10 17:03:54,089:INFO:Uploading model into container now
2024-07-10 17:03:54,089:INFO:_master_model_container: 33
2024-07-10 17:03:54,089:INFO:_display_container: 6
2024-07-10 17:03:54,089:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2024-07-10 17:03:54,090:INFO:create_model() successfully completed......................................
2024-07-10 17:03:54,174:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:54,175:INFO:Creating metrics dataframe
2024-07-10 17:03:54,184:INFO:Initializing Decision Tree Regressor
2024-07-10 17:03:54,184:INFO:Total runtime is 0.05127665599187216 minutes
2024-07-10 17:03:54,187:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:54,187:INFO:Initializing create_model()
2024-07-10 17:03:54,188:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:54,188:INFO:Checking exceptions
2024-07-10 17:03:54,188:INFO:Importing libraries
2024-07-10 17:03:54,188:INFO:Copying training dataset
2024-07-10 17:03:54,191:INFO:Defining folds
2024-07-10 17:03:54,191:INFO:Declaring metric variables
2024-07-10 17:03:54,194:INFO:Importing untrained model
2024-07-10 17:03:54,197:INFO:Decision Tree Regressor Imported successfully
2024-07-10 17:03:54,203:INFO:Starting cross validation
2024-07-10 17:03:54,205:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:54,354:INFO:Calculating mean and std
2024-07-10 17:03:54,354:INFO:Creating metrics dataframe
2024-07-10 17:03:54,356:INFO:Uploading results into container
2024-07-10 17:03:54,357:INFO:Uploading model into container now
2024-07-10 17:03:54,357:INFO:_master_model_container: 34
2024-07-10 17:03:54,357:INFO:_display_container: 6
2024-07-10 17:03:54,358:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2024-07-10 17:03:54,358:INFO:create_model() successfully completed......................................
2024-07-10 17:03:54,439:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:54,439:INFO:Creating metrics dataframe
2024-07-10 17:03:54,446:INFO:Initializing Random Forest Regressor
2024-07-10 17:03:54,446:INFO:Total runtime is 0.05564446051915487 minutes
2024-07-10 17:03:54,450:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:54,451:INFO:Initializing create_model()
2024-07-10 17:03:54,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:54,451:INFO:Checking exceptions
2024-07-10 17:03:54,451:INFO:Importing libraries
2024-07-10 17:03:54,451:INFO:Copying training dataset
2024-07-10 17:03:54,454:INFO:Defining folds
2024-07-10 17:03:54,455:INFO:Declaring metric variables
2024-07-10 17:03:54,457:INFO:Importing untrained model
2024-07-10 17:03:54,459:INFO:Random Forest Regressor Imported successfully
2024-07-10 17:03:54,466:INFO:Starting cross validation
2024-07-10 17:03:54,468:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:55,045:INFO:Calculating mean and std
2024-07-10 17:03:55,046:INFO:Creating metrics dataframe
2024-07-10 17:03:55,050:INFO:Uploading results into container
2024-07-10 17:03:55,051:INFO:Uploading model into container now
2024-07-10 17:03:55,051:INFO:_master_model_container: 35
2024-07-10 17:03:55,051:INFO:_display_container: 6
2024-07-10 17:03:55,051:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2024-07-10 17:03:55,051:INFO:create_model() successfully completed......................................
2024-07-10 17:03:55,134:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:55,134:INFO:Creating metrics dataframe
2024-07-10 17:03:55,141:INFO:Initializing Extra Trees Regressor
2024-07-10 17:03:55,142:INFO:Total runtime is 0.06721868912378948 minutes
2024-07-10 17:03:55,143:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:55,144:INFO:Initializing create_model()
2024-07-10 17:03:55,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:55,144:INFO:Checking exceptions
2024-07-10 17:03:55,144:INFO:Importing libraries
2024-07-10 17:03:55,144:INFO:Copying training dataset
2024-07-10 17:03:55,149:INFO:Defining folds
2024-07-10 17:03:55,149:INFO:Declaring metric variables
2024-07-10 17:03:55,152:INFO:Importing untrained model
2024-07-10 17:03:55,155:INFO:Extra Trees Regressor Imported successfully
2024-07-10 17:03:55,162:INFO:Starting cross validation
2024-07-10 17:03:55,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:55,700:INFO:Calculating mean and std
2024-07-10 17:03:55,701:INFO:Creating metrics dataframe
2024-07-10 17:03:55,702:INFO:Uploading results into container
2024-07-10 17:03:55,703:INFO:Uploading model into container now
2024-07-10 17:03:55,703:INFO:_master_model_container: 36
2024-07-10 17:03:55,703:INFO:_display_container: 6
2024-07-10 17:03:55,704:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2024-07-10 17:03:55,704:INFO:create_model() successfully completed......................................
2024-07-10 17:03:55,789:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:55,789:INFO:Creating metrics dataframe
2024-07-10 17:03:55,800:INFO:Initializing AdaBoost Regressor
2024-07-10 17:03:55,800:INFO:Total runtime is 0.07820208072662355 minutes
2024-07-10 17:03:55,803:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:55,803:INFO:Initializing create_model()
2024-07-10 17:03:55,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:55,804:INFO:Checking exceptions
2024-07-10 17:03:55,804:INFO:Importing libraries
2024-07-10 17:03:55,804:INFO:Copying training dataset
2024-07-10 17:03:55,807:INFO:Defining folds
2024-07-10 17:03:55,807:INFO:Declaring metric variables
2024-07-10 17:03:55,809:INFO:Importing untrained model
2024-07-10 17:03:55,812:INFO:AdaBoost Regressor Imported successfully
2024-07-10 17:03:55,818:INFO:Starting cross validation
2024-07-10 17:03:55,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:56,093:INFO:Calculating mean and std
2024-07-10 17:03:56,094:INFO:Creating metrics dataframe
2024-07-10 17:03:56,096:INFO:Uploading results into container
2024-07-10 17:03:56,097:INFO:Uploading model into container now
2024-07-10 17:03:56,097:INFO:_master_model_container: 37
2024-07-10 17:03:56,097:INFO:_display_container: 6
2024-07-10 17:03:56,098:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2024-07-10 17:03:56,098:INFO:create_model() successfully completed......................................
2024-07-10 17:03:56,185:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:56,185:INFO:Creating metrics dataframe
2024-07-10 17:03:56,193:INFO:Initializing Gradient Boosting Regressor
2024-07-10 17:03:56,194:INFO:Total runtime is 0.08476446469624839 minutes
2024-07-10 17:03:56,197:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:56,198:INFO:Initializing create_model()
2024-07-10 17:03:56,198:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:56,198:INFO:Checking exceptions
2024-07-10 17:03:56,198:INFO:Importing libraries
2024-07-10 17:03:56,198:INFO:Copying training dataset
2024-07-10 17:03:56,203:INFO:Defining folds
2024-07-10 17:03:56,203:INFO:Declaring metric variables
2024-07-10 17:03:56,205:INFO:Importing untrained model
2024-07-10 17:03:56,208:INFO:Gradient Boosting Regressor Imported successfully
2024-07-10 17:03:56,213:INFO:Starting cross validation
2024-07-10 17:03:56,215:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:56,547:INFO:Calculating mean and std
2024-07-10 17:03:56,548:INFO:Creating metrics dataframe
2024-07-10 17:03:56,550:INFO:Uploading results into container
2024-07-10 17:03:56,551:INFO:Uploading model into container now
2024-07-10 17:03:56,551:INFO:_master_model_container: 38
2024-07-10 17:03:56,551:INFO:_display_container: 6
2024-07-10 17:03:56,552:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-10 17:03:56,552:INFO:create_model() successfully completed......................................
2024-07-10 17:03:56,635:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:56,635:INFO:Creating metrics dataframe
2024-07-10 17:03:56,646:INFO:Initializing Extreme Gradient Boosting
2024-07-10 17:03:56,646:INFO:Total runtime is 0.09230112632115683 minutes
2024-07-10 17:03:56,649:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:56,649:INFO:Initializing create_model()
2024-07-10 17:03:56,649:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:56,649:INFO:Checking exceptions
2024-07-10 17:03:56,649:INFO:Importing libraries
2024-07-10 17:03:56,649:INFO:Copying training dataset
2024-07-10 17:03:56,653:INFO:Defining folds
2024-07-10 17:03:56,653:INFO:Declaring metric variables
2024-07-10 17:03:56,655:INFO:Importing untrained model
2024-07-10 17:03:56,657:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 17:03:56,662:INFO:Starting cross validation
2024-07-10 17:03:56,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:56,931:INFO:Calculating mean and std
2024-07-10 17:03:56,932:INFO:Creating metrics dataframe
2024-07-10 17:03:56,934:INFO:Uploading results into container
2024-07-10 17:03:56,935:INFO:Uploading model into container now
2024-07-10 17:03:56,935:INFO:_master_model_container: 39
2024-07-10 17:03:56,935:INFO:_display_container: 6
2024-07-10 17:03:56,936:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:03:56,937:INFO:create_model() successfully completed......................................
2024-07-10 17:03:57,021:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:57,021:INFO:Creating metrics dataframe
2024-07-10 17:03:57,030:INFO:Initializing Light Gradient Boosting Machine
2024-07-10 17:03:57,030:INFO:Total runtime is 0.09869673649470014 minutes
2024-07-10 17:03:57,034:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:57,035:INFO:Initializing create_model()
2024-07-10 17:03:57,035:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:57,035:INFO:Checking exceptions
2024-07-10 17:03:57,035:INFO:Importing libraries
2024-07-10 17:03:57,035:INFO:Copying training dataset
2024-07-10 17:03:57,040:INFO:Defining folds
2024-07-10 17:03:57,040:INFO:Declaring metric variables
2024-07-10 17:03:57,043:INFO:Importing untrained model
2024-07-10 17:03:57,046:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-10 17:03:57,052:INFO:Starting cross validation
2024-07-10 17:03:57,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:58,772:INFO:Calculating mean and std
2024-07-10 17:03:58,773:INFO:Creating metrics dataframe
2024-07-10 17:03:58,776:INFO:Uploading results into container
2024-07-10 17:03:58,777:INFO:Uploading model into container now
2024-07-10 17:03:58,777:INFO:_master_model_container: 40
2024-07-10 17:03:58,777:INFO:_display_container: 6
2024-07-10 17:03:58,778:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2024-07-10 17:03:58,778:INFO:create_model() successfully completed......................................
2024-07-10 17:03:58,871:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:58,872:INFO:Creating metrics dataframe
2024-07-10 17:03:58,880:INFO:Initializing Dummy Regressor
2024-07-10 17:03:58,880:INFO:Total runtime is 0.12953525384267173 minutes
2024-07-10 17:03:58,883:INFO:SubProcess create_model() called ==================================
2024-07-10 17:03:58,883:INFO:Initializing create_model()
2024-07-10 17:03:58,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B3B7970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:58,883:INFO:Checking exceptions
2024-07-10 17:03:58,883:INFO:Importing libraries
2024-07-10 17:03:58,883:INFO:Copying training dataset
2024-07-10 17:03:58,887:INFO:Defining folds
2024-07-10 17:03:58,887:INFO:Declaring metric variables
2024-07-10 17:03:58,890:INFO:Importing untrained model
2024-07-10 17:03:58,892:INFO:Dummy Regressor Imported successfully
2024-07-10 17:03:58,897:INFO:Starting cross validation
2024-07-10 17:03:58,898:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:03:59,041:INFO:Calculating mean and std
2024-07-10 17:03:59,043:INFO:Creating metrics dataframe
2024-07-10 17:03:59,044:INFO:Uploading results into container
2024-07-10 17:03:59,044:INFO:Uploading model into container now
2024-07-10 17:03:59,045:INFO:_master_model_container: 41
2024-07-10 17:03:59,045:INFO:_display_container: 6
2024-07-10 17:03:59,045:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2024-07-10 17:03:59,045:INFO:create_model() successfully completed......................................
2024-07-10 17:03:59,129:INFO:SubProcess create_model() end ==================================
2024-07-10 17:03:59,129:INFO:Creating metrics dataframe
2024-07-10 17:03:59,138:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-07-10 17:03:59,146:INFO:Initializing create_model()
2024-07-10 17:03:59,146:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:03:59,146:INFO:Checking exceptions
2024-07-10 17:03:59,148:INFO:Importing libraries
2024-07-10 17:03:59,148:INFO:Copying training dataset
2024-07-10 17:03:59,151:INFO:Defining folds
2024-07-10 17:03:59,151:INFO:Declaring metric variables
2024-07-10 17:03:59,152:INFO:Importing untrained model
2024-07-10 17:03:59,152:INFO:Declaring custom model
2024-07-10 17:03:59,152:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 17:03:59,154:INFO:Cross validation set to False
2024-07-10 17:03:59,154:INFO:Fitting Model
2024-07-10 17:03:59,338:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:03:59,338:INFO:create_model() successfully completed......................................
2024-07-10 17:03:59,471:INFO:_master_model_container: 41
2024-07-10 17:03:59,471:INFO:_display_container: 6
2024-07-10 17:03:59,472:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:03:59,472:INFO:compare_models() successfully completed......................................
2024-07-10 17:05:05,362:INFO:Initializing create_model()
2024-07-10 17:05:05,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:05:05,363:INFO:Checking exceptions
2024-07-10 17:05:05,376:INFO:Importing libraries
2024-07-10 17:05:05,376:INFO:Copying training dataset
2024-07-10 17:05:05,381:INFO:Defining folds
2024-07-10 17:05:05,381:INFO:Declaring metric variables
2024-07-10 17:05:05,384:INFO:Importing untrained model
2024-07-10 17:05:05,386:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 17:05:05,391:INFO:Starting cross validation
2024-07-10 17:05:05,394:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:05:05,666:INFO:Calculating mean and std
2024-07-10 17:05:05,667:INFO:Creating metrics dataframe
2024-07-10 17:05:05,670:INFO:Finalizing model
2024-07-10 17:05:05,852:INFO:Uploading results into container
2024-07-10 17:05:05,853:INFO:Uploading model into container now
2024-07-10 17:05:05,862:INFO:_master_model_container: 42
2024-07-10 17:05:05,862:INFO:_display_container: 7
2024-07-10 17:05:05,863:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:05:05,863:INFO:create_model() successfully completed......................................
2024-07-10 17:05:21,215:INFO:Initializing evaluate_model()
2024-07-10 17:05:21,216:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A7B3B79D0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-10 17:05:29,907:INFO:Initializing create_model()
2024-07-10 17:05:29,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:05:29,907:INFO:Checking exceptions
2024-07-10 17:05:29,918:INFO:Importing libraries
2024-07-10 17:05:29,919:INFO:Copying training dataset
2024-07-10 17:05:29,925:INFO:Defining folds
2024-07-10 17:05:29,925:INFO:Declaring metric variables
2024-07-10 17:05:29,927:INFO:Importing untrained model
2024-07-10 17:05:29,930:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 17:05:29,935:INFO:Starting cross validation
2024-07-10 17:05:29,937:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:05:30,203:INFO:Calculating mean and std
2024-07-10 17:05:30,203:INFO:Creating metrics dataframe
2024-07-10 17:05:30,207:INFO:Finalizing model
2024-07-10 17:05:30,387:INFO:Uploading results into container
2024-07-10 17:05:30,388:INFO:Uploading model into container now
2024-07-10 17:05:30,395:INFO:_master_model_container: 43
2024-07-10 17:05:30,396:INFO:_display_container: 8
2024-07-10 17:05:30,396:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:05:30,396:INFO:create_model() successfully completed......................................
2024-07-10 17:05:34,363:INFO:Initializing evaluate_model()
2024-07-10 17:05:34,363:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A7B3B79D0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-10 17:05:42,916:INFO:Initializing tune_model()
2024-07-10 17:05:42,916:INFO:tune_model(estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>)
2024-07-10 17:05:42,916:INFO:Checking exceptions
2024-07-10 17:05:42,930:INFO:Copying training dataset
2024-07-10 17:05:42,934:INFO:Checking base model
2024-07-10 17:05:42,934:INFO:Base model : Extreme Gradient Boosting
2024-07-10 17:05:42,937:INFO:Declaring metric variables
2024-07-10 17:05:42,939:INFO:Defining Hyperparameters
2024-07-10 17:05:43,067:INFO:Tuning with n_jobs=-1
2024-07-10 17:05:43,067:INFO:Initializing RandomizedSearchCV
2024-07-10 17:05:45,107:INFO:best_params: {'actual_estimator__subsample': 0.2, 'actual_estimator__scale_pos_weight': 37.7, 'actual_estimator__reg_lambda': 0.2, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__n_estimators': 220, 'actual_estimator__min_child_weight': 4, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.9}
2024-07-10 17:05:45,108:INFO:Hyperparameter search completed
2024-07-10 17:05:45,108:INFO:SubProcess create_model() called ==================================
2024-07-10 17:05:45,109:INFO:Initializing create_model()
2024-07-10 17:05:45,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7B77B280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.2, 'scale_pos_weight': 37.7, 'reg_lambda': 0.2, 'reg_alpha': 0.0001, 'n_estimators': 220, 'min_child_weight': 4, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bytree': 0.9})
2024-07-10 17:05:45,109:INFO:Checking exceptions
2024-07-10 17:05:45,109:INFO:Importing libraries
2024-07-10 17:05:45,109:INFO:Copying training dataset
2024-07-10 17:05:45,116:INFO:Defining folds
2024-07-10 17:05:45,116:INFO:Declaring metric variables
2024-07-10 17:05:45,119:INFO:Importing untrained model
2024-07-10 17:05:45,120:INFO:Declaring custom model
2024-07-10 17:05:45,123:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 17:05:45,128:INFO:Starting cross validation
2024-07-10 17:05:45,130:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:05:45,500:INFO:Calculating mean and std
2024-07-10 17:05:45,501:INFO:Creating metrics dataframe
2024-07-10 17:05:45,505:INFO:Finalizing model
2024-07-10 17:05:45,896:INFO:Uploading results into container
2024-07-10 17:05:45,897:INFO:Uploading model into container now
2024-07-10 17:05:45,897:INFO:_master_model_container: 44
2024-07-10 17:05:45,897:INFO:_display_container: 9
2024-07-10 17:05:45,898:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.05, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=10, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=220, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:05:45,898:INFO:create_model() successfully completed......................................
2024-07-10 17:05:46,023:INFO:SubProcess create_model() end ==================================
2024-07-10 17:05:46,023:INFO:choose_better activated
2024-07-10 17:05:46,026:INFO:SubProcess create_model() called ==================================
2024-07-10 17:05:46,027:INFO:Initializing create_model()
2024-07-10 17:05:46,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7D5D3D30>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 17:05:46,027:INFO:Checking exceptions
2024-07-10 17:05:46,028:INFO:Importing libraries
2024-07-10 17:05:46,028:INFO:Copying training dataset
2024-07-10 17:05:46,032:INFO:Defining folds
2024-07-10 17:05:46,032:INFO:Declaring metric variables
2024-07-10 17:05:46,032:INFO:Importing untrained model
2024-07-10 17:05:46,032:INFO:Declaring custom model
2024-07-10 17:05:46,033:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 17:05:46,033:INFO:Starting cross validation
2024-07-10 17:05:46,035:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 17:05:46,290:INFO:Calculating mean and std
2024-07-10 17:05:46,290:INFO:Creating metrics dataframe
2024-07-10 17:05:46,292:INFO:Finalizing model
2024-07-10 17:05:46,464:INFO:Uploading results into container
2024-07-10 17:05:46,465:INFO:Uploading model into container now
2024-07-10 17:05:46,465:INFO:_master_model_container: 45
2024-07-10 17:05:46,465:INFO:_display_container: 10
2024-07-10 17:05:46,466:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:05:46,466:INFO:create_model() successfully completed......................................
2024-07-10 17:05:46,587:INFO:SubProcess create_model() end ==================================
2024-07-10 17:05:46,588:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...) result for R2 is 0.7553
2024-07-10 17:05:46,588:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.05, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=10, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=220, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...) result for R2 is 0.7289
2024-07-10 17:05:46,589:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...) is best model
2024-07-10 17:05:46,589:INFO:choose_better completed
2024-07-10 17:05:46,589:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-10 17:05:46,596:INFO:_master_model_container: 45
2024-07-10 17:05:46,596:INFO:_display_container: 9
2024-07-10 17:05:46,596:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 17:05:46,597:INFO:tune_model() successfully completed......................................
2024-07-10 17:05:55,448:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 50672 (\N{HANGUL SYLLABLE YEON}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,448:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 49885 (\N{HANGUL SYLLABLE SIG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,448:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 45380 (\N{HANGUL SYLLABLE NYEON}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,449:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 51452 (\N{HANGUL SYLLABLE JU}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,449:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 54665 (\N{HANGUL SYLLABLE HAENG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,449:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 44144 (\N{HANGUL SYLLABLE GEO}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,449:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 47532 (\N{HANGUL SYLLABLE RI}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,449:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 48176 (\N{HANGUL SYLLABLE BAE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,449:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 44592 (\N{HANGUL SYLLABLE GI}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,449:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 47049 (\N{HANGUL SYLLABLE RYANG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,449:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 52264 (\N{HANGUL SYLLABLE CA}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,450:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 51333 (\N{HANGUL SYLLABLE JONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,450:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 51456 (\N{HANGUL SYLLABLE JUN}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,450:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 51473 (\N{HANGUL SYLLABLE JUNG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,450:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 54805 (\N{HANGUL SYLLABLE HYEONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,450:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 45824 (\N{HANGUL SYLLABLE DAE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,450:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 49849 (\N{HANGUL SYLLABLE SEUNG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,451:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 50857 (\N{HANGUL SYLLABLE YONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,451:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 44221 (\N{HANGUL SYLLABLE GYEONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,453:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 49548 (\N{HANGUL SYLLABLE SO}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,455:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 54868 (\N{HANGUL SYLLABLE HWA}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,455:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 47932 (\N{HANGUL SYLLABLE MUL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,455:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 54633 (\N{HANGUL SYLLABLE HAB}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,456:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 49828 (\N{HANGUL SYLLABLE SEU}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,456:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 54252 (\N{HANGUL SYLLABLE PO}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,456:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 52768 (\N{HANGUL SYLLABLE CEU}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,457:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 52852 (\N{HANGUL SYLLABLE KA}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,457:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 47308 (\N{HANGUL SYLLABLE RYO}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,457:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 44032 (\N{HANGUL SYLLABLE GA}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,457:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 49556 (\N{HANGUL SYLLABLE SOL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,457:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 47536 (\N{HANGUL SYLLABLE RIN}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,457:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 51204 (\N{HANGUL SYLLABLE JEON}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,458:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 46356 (\N{HANGUL SYLLABLE DI}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,458:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 51236 (\N{HANGUL SYLLABLE JEL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,458:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 54616 (\N{HANGUL SYLLABLE HA}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,458:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 51060 (\N{HANGUL SYLLABLE I}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,458:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 48652 (\N{HANGUL SYLLABLE BEU}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,458:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 46300 (\N{HANGUL SYLLABLE DEU}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,459:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 53440 (\N{HANGUL SYLLABLE TA}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,459:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 48320 (\N{HANGUL SYLLABLE BYEON}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,459:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 49549 (\N{HANGUL SYLLABLE SOG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,459:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 50724 (\N{HANGUL SYLLABLE O}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,459:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 53664 (\N{HANGUL SYLLABLE TO}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,460:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 50517 (\N{HANGUL SYLLABLE AB}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,460:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 47448 (\N{HANGUL SYLLABLE RYU}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,460:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 51200 (\N{HANGUL SYLLABLE JEO}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,460:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 45817 (\N{HANGUL SYLLABLE DANG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,461:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 49353 (\N{HANGUL SYLLABLE SAEG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,461:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 49345 (\N{HANGUL SYLLABLE SANG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,461:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 48516 (\N{HANGUL SYLLABLE BUN}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,461:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 54028 (\N{HANGUL SYLLABLE PA}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,461:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 46993 (\N{HANGUL SYLLABLE RANG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,462:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 55152 (\N{HANGUL SYLLABLE HYIN}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,462:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 54924 (\N{HANGUL SYLLABLE HOE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,463:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 44160 (\N{HANGUL SYLLABLE GEOM}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,463:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 51221 (\N{HANGUL SYLLABLE JEONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,463:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 48744 (\N{HANGUL SYLLABLE BBAL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,463:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 44053 (\N{HANGUL SYLLABLE GANG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,464:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 44040 (\N{HANGUL SYLLABLE GAL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,464:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 52488 (\N{HANGUL SYLLABLE CO}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,464:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 47197 (\N{HANGUL SYLLABLE ROG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,465:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 45432 (\N{HANGUL SYLLABLE NO}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,465:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 53685 (\N{HANGUL SYLLABLE TONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,465:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 54413 (\N{HANGUL SYLLABLE PUNG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,465:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 49884 (\N{HANGUL SYLLABLE SI}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,465:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 53944 (\N{HANGUL SYLLABLE TEU}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,466:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 50676 (\N{HANGUL SYLLABLE YEOL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,466:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 46041 (\N{HANGUL SYLLABLE DONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,466:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 47105 (\N{HANGUL SYLLABLE REONG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,466:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 53356 (\N{HANGUL SYLLABLE KEU}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,466:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 47560 (\N{HANGUL SYLLABLE MA}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,467:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 47336 (\N{HANGUL SYLLABLE RU}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,467:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 51592 (\N{HANGUL SYLLABLE JEU}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,467:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 52968 (\N{HANGUL SYLLABLE KEON}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,467:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 47204 (\N{HANGUL SYLLABLE ROL}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,467:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 51453 (\N{HANGUL SYLLABLE JUG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,467:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 48169 (\N{HANGUL SYLLABLE BANG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,469:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 44256 (\N{HANGUL SYLLABLE GO}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,469:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 49440 (\N{HANGUL SYLLABLE SEON}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,469:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 54980 (\N{HANGUL SYLLABLE HU}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,469:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 52769 (\N{HANGUL SYLLABLE CEUG}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,469:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 48372 (\N{HANGUL SYLLABLE BO}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,469:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 53596 (\N{HANGUL SYLLABLE TEM}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,469:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 45236 (\N{HANGUL SYLLABLE NAE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,469:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 48708 (\N{HANGUL SYLLABLE BI}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,469:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 44172 (\N{HANGUL SYLLABLE GE}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,469:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 49496 (\N{HANGUL SYLLABLE SYEON}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,469:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 54532 (\N{HANGUL SYLLABLE PEU}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,470:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 47784 (\N{HANGUL SYLLABLE MO}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,470:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 45768 (\N{HANGUL SYLLABLE NI}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,470:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 53552 (\N{HANGUL SYLLABLE TEO}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,470:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 50741 (\N{HANGUL SYLLABLE OB}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,470:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 44079 (\N{HANGUL SYLLABLE GAES}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 17:05:55,470:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\IPython\core\pylabtools.py:170: UserWarning: Glyph 49688 (\N{HANGUL SYLLABLE SU}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)

2024-07-10 18:37:25,128:INFO:PyCaret RegressionExperiment
2024-07-10 18:37:25,128:INFO:Logging name: reg-default-name
2024-07-10 18:37:25,128:INFO:ML Usecase: MLUsecase.REGRESSION
2024-07-10 18:37:25,129:INFO:version 3.3.2
2024-07-10 18:37:25,129:INFO:Initializing setup()
2024-07-10 18:37:25,129:INFO:self.USI: fc77
2024-07-10 18:37:25,129:INFO:self._variable_keys: {'n_jobs_param', 'pipeline', 'y_train', 'idx', 'fold_shuffle_param', '_available_plots', '_ml_usecase', 'memory', 'exp_name_log', 'log_plots_param', 'X_train', 'gpu_n_jobs_param', 'seed', 'USI', 'html_param', 'X', 'data', 'X_test', 'logging_param', 'y_test', 'target_param', 'transform_target_param', 'exp_id', 'y', 'fold_generator', 'gpu_param', 'fold_groups_param'}
2024-07-10 18:37:25,129:INFO:Checking environment
2024-07-10 18:37:25,129:INFO:python_version: 3.10.14
2024-07-10 18:37:25,129:INFO:python_build: ('main', 'May  6 2024 19:44:50')
2024-07-10 18:37:25,130:INFO:machine: AMD64
2024-07-10 18:37:25,130:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-10 18:37:25,136:INFO:Memory: svmem(total=34004869120, available=16701792256, percent=50.9, used=17303076864, free=16701792256)
2024-07-10 18:37:25,136:INFO:Physical Core: 16
2024-07-10 18:37:25,136:INFO:Logical Core: 22
2024-07-10 18:37:25,136:INFO:Checking libraries
2024-07-10 18:37:25,136:INFO:System:
2024-07-10 18:37:25,136:INFO:    python: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]
2024-07-10 18:37:25,136:INFO:executable: c:\Users\Admin\miniconda3\envs\gumi_env310\python.exe
2024-07-10 18:37:25,136:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-10 18:37:25,137:INFO:PyCaret required dependencies:
2024-07-10 18:37:25,137:INFO:                 pip: 24.0
2024-07-10 18:37:25,137:INFO:          setuptools: 69.5.1
2024-07-10 18:37:25,137:INFO:             pycaret: 3.3.2
2024-07-10 18:37:25,137:INFO:             IPython: 8.25.0
2024-07-10 18:37:25,137:INFO:          ipywidgets: 8.1.3
2024-07-10 18:37:25,137:INFO:                tqdm: 4.66.4
2024-07-10 18:37:25,137:INFO:               numpy: 1.26.4
2024-07-10 18:37:25,137:INFO:              pandas: 2.1.4
2024-07-10 18:37:25,137:INFO:              jinja2: 3.1.4
2024-07-10 18:37:25,137:INFO:               scipy: 1.11.4
2024-07-10 18:37:25,137:INFO:              joblib: 1.3.2
2024-07-10 18:37:25,137:INFO:             sklearn: 1.4.2
2024-07-10 18:37:25,137:INFO:                pyod: 2.0.1
2024-07-10 18:37:25,137:INFO:            imblearn: 0.12.3
2024-07-10 18:37:25,137:INFO:   category_encoders: 2.6.3
2024-07-10 18:37:25,137:INFO:            lightgbm: 4.4.0
2024-07-10 18:37:25,137:INFO:               numba: 0.60.0
2024-07-10 18:37:25,137:INFO:            requests: 2.32.3
2024-07-10 18:37:25,137:INFO:          matplotlib: 3.7.5
2024-07-10 18:37:25,137:INFO:          scikitplot: 0.3.7
2024-07-10 18:37:25,137:INFO:         yellowbrick: 1.5
2024-07-10 18:37:25,137:INFO:              plotly: 5.22.0
2024-07-10 18:37:25,137:INFO:    plotly-resampler: Not installed
2024-07-10 18:37:25,137:INFO:             kaleido: 0.2.1
2024-07-10 18:37:25,137:INFO:           schemdraw: 0.15
2024-07-10 18:37:25,137:INFO:         statsmodels: 0.14.2
2024-07-10 18:37:25,137:INFO:              sktime: 0.26.0
2024-07-10 18:37:25,137:INFO:               tbats: 1.1.3
2024-07-10 18:37:25,137:INFO:            pmdarima: 2.0.4
2024-07-10 18:37:25,137:INFO:              psutil: 5.9.8
2024-07-10 18:37:25,137:INFO:          markupsafe: 2.1.5
2024-07-10 18:37:25,137:INFO:             pickle5: Not installed
2024-07-10 18:37:25,137:INFO:         cloudpickle: 3.0.0
2024-07-10 18:37:25,137:INFO:         deprecation: 2.1.0
2024-07-10 18:37:25,137:INFO:              xxhash: 3.4.1
2024-07-10 18:37:25,137:INFO:           wurlitzer: Not installed
2024-07-10 18:37:25,138:INFO:PyCaret optional dependencies:
2024-07-10 18:37:25,138:INFO:                shap: Not installed
2024-07-10 18:37:25,138:INFO:           interpret: Not installed
2024-07-10 18:37:25,138:INFO:                umap: Not installed
2024-07-10 18:37:25,138:INFO:     ydata_profiling: Not installed
2024-07-10 18:37:25,138:INFO:  explainerdashboard: Not installed
2024-07-10 18:37:25,138:INFO:             autoviz: Not installed
2024-07-10 18:37:25,138:INFO:           fairlearn: Not installed
2024-07-10 18:37:25,138:INFO:          deepchecks: Not installed
2024-07-10 18:37:25,138:INFO:             xgboost: 2.1.0
2024-07-10 18:37:25,138:INFO:            catboost: Not installed
2024-07-10 18:37:25,138:INFO:              kmodes: Not installed
2024-07-10 18:37:25,138:INFO:             mlxtend: Not installed
2024-07-10 18:37:25,138:INFO:       statsforecast: Not installed
2024-07-10 18:37:25,138:INFO:        tune_sklearn: Not installed
2024-07-10 18:37:25,138:INFO:                 ray: Not installed
2024-07-10 18:37:25,138:INFO:            hyperopt: Not installed
2024-07-10 18:37:25,138:INFO:              optuna: 3.6.1
2024-07-10 18:37:25,138:INFO:               skopt: Not installed
2024-07-10 18:37:25,138:INFO:              mlflow: Not installed
2024-07-10 18:37:25,138:INFO:              gradio: Not installed
2024-07-10 18:37:25,138:INFO:             fastapi: Not installed
2024-07-10 18:37:25,138:INFO:             uvicorn: Not installed
2024-07-10 18:37:25,138:INFO:              m2cgen: Not installed
2024-07-10 18:37:25,138:INFO:           evidently: Not installed
2024-07-10 18:37:25,138:INFO:               fugue: Not installed
2024-07-10 18:37:25,138:INFO:           streamlit: Not installed
2024-07-10 18:37:25,138:INFO:             prophet: Not installed
2024-07-10 18:37:25,138:INFO:None
2024-07-10 18:37:25,138:INFO:Set up data.
2024-07-10 18:37:25,148:INFO:Set up folding strategy.
2024-07-10 18:37:25,149:INFO:Set up train/test split.
2024-07-10 18:37:25,153:INFO:Set up index.
2024-07-10 18:37:25,154:INFO:Assigning column types.
2024-07-10 18:37:25,158:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-10 18:37:25,158:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,161:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,164:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,197:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,221:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,222:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:25,223:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:25,224:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,227:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,230:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,263:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,289:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,290:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:25,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:25,292:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-07-10 18:37:25,295:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,298:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,330:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,355:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:25,357:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:25,359:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,362:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,398:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,422:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,422:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:25,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:25,424:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-07-10 18:37:25,430:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,467:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,494:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:25,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:25,502:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,537:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,564:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,564:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:25,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:25,566:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-07-10 18:37:25,605:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,630:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,631:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:25,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:25,674:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,699:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,699:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:25,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:25,701:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-10 18:37:25,739:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,765:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:25,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:25,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-07-10 18:37:25,831:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:25,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:25,832:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-07-10 18:37:25,896:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:25,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:25,968:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:25,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:25,970:INFO:Preparing preprocessing pipeline...
2024-07-10 18:37:25,970:INFO:Set up simple imputation.
2024-07-10 18:37:25,973:INFO:Set up encoding of ordinal features.
2024-07-10 18:37:25,974:INFO:Set up encoding of categorical features.
2024-07-10 18:37:25,975:INFO:Set up column name cleaning.
2024-07-10 18:37:26,067:INFO:Finished creating preprocessing pipeline.
2024-07-10 18:37:26,077:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Admin\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['연식(년)', '주행거리(km)', '배기량(cc)',
                                             '압류_저당', '통풍시트(1열/2열)', '전동식 트렁크',
                                             '스마트 크루즈 컨트롤', '가죽 시트',
                                             '전방 주차거리 경고', '열선시트(1열/2열)',
                                             '후측방 경보 시스템', '내비게이션', '선루프',
                                             '후방 모니터', '옵션_갯수'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              f...
                                    include=['차종', '연료', '변속기', '색상_중분류'],
                                    transformer=OneHotEncoder(cols=['차종', '연료',
                                                                    '변속기',
                                                                    '색상_중분류'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-07-10 18:37:26,077:INFO:Creating final display dataframe.
2024-07-10 18:37:26,320:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                가격
2                   Target type        Regression
3           Original data shape        (1760, 23)
4        Transformed data shape        (1760, 52)
5   Transformed train set shape        (1232, 52)
6    Transformed test set shape         (528, 52)
7               Ignore features                 2
8              Numeric features                15
9          Categorical features                 5
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              fc77
2024-07-10 18:37:26,389:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:26,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:26,455:INFO:Soft dependency imported: xgboost: 2.1.0
2024-07-10 18:37:26,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-10 18:37:26,458:INFO:setup() successfully completed in 1.33s...............
2024-07-10 18:37:26,461:INFO:Initializing compare_models()
2024-07-10 18:37:26,461:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-07-10 18:37:26,462:INFO:Checking exceptions
2024-07-10 18:37:26,463:INFO:Preparing display monitor
2024-07-10 18:37:26,482:INFO:Initializing Linear Regression
2024-07-10 18:37:26,482:INFO:Total runtime is 0.0 minutes
2024-07-10 18:37:26,485:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:26,485:INFO:Initializing create_model()
2024-07-10 18:37:26,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:26,486:INFO:Checking exceptions
2024-07-10 18:37:26,486:INFO:Importing libraries
2024-07-10 18:37:26,486:INFO:Copying training dataset
2024-07-10 18:37:26,490:INFO:Defining folds
2024-07-10 18:37:26,491:INFO:Declaring metric variables
2024-07-10 18:37:26,493:INFO:Importing untrained model
2024-07-10 18:37:26,496:INFO:Linear Regression Imported successfully
2024-07-10 18:37:26,501:INFO:Starting cross validation
2024-07-10 18:37:26,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:29,873:INFO:Calculating mean and std
2024-07-10 18:37:29,875:INFO:Creating metrics dataframe
2024-07-10 18:37:29,878:INFO:Uploading results into container
2024-07-10 18:37:29,878:INFO:Uploading model into container now
2024-07-10 18:37:29,879:INFO:_master_model_container: 1
2024-07-10 18:37:29,879:INFO:_display_container: 2
2024-07-10 18:37:29,880:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, positive=False)
2024-07-10 18:37:29,880:INFO:create_model() successfully completed......................................
2024-07-10 18:37:30,162:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:30,162:INFO:Creating metrics dataframe
2024-07-10 18:37:30,168:INFO:Initializing Lasso Regression
2024-07-10 18:37:30,168:INFO:Total runtime is 0.061439788341522215 minutes
2024-07-10 18:37:30,172:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:30,173:INFO:Initializing create_model()
2024-07-10 18:37:30,173:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:30,173:INFO:Checking exceptions
2024-07-10 18:37:30,173:INFO:Importing libraries
2024-07-10 18:37:30,173:INFO:Copying training dataset
2024-07-10 18:37:30,179:INFO:Defining folds
2024-07-10 18:37:30,179:INFO:Declaring metric variables
2024-07-10 18:37:30,182:INFO:Importing untrained model
2024-07-10 18:37:30,184:INFO:Lasso Regression Imported successfully
2024-07-10 18:37:30,189:INFO:Starting cross validation
2024-07-10 18:37:30,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:32,731:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.336e+16, tolerance: 7.651e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 18:37:32,739:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.216e+16, tolerance: 9.691e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 18:37:32,740:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.662e+16, tolerance: 9.620e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 18:37:32,752:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.519e+16, tolerance: 9.686e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 18:37:32,754:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.420e+16, tolerance: 9.664e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 18:37:32,754:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.566e+16, tolerance: 9.235e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 18:37:32,767:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e+16, tolerance: 9.689e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 18:37:32,782:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.300e+16, tolerance: 9.690e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 18:37:32,794:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e+16, tolerance: 5.348e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 18:37:32,798:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e+16, tolerance: 9.667e+13
  model = cd_fast.enet_coordinate_descent(

2024-07-10 18:37:32,832:INFO:Calculating mean and std
2024-07-10 18:37:32,834:INFO:Creating metrics dataframe
2024-07-10 18:37:32,837:INFO:Uploading results into container
2024-07-10 18:37:32,838:INFO:Uploading model into container now
2024-07-10 18:37:32,838:INFO:_master_model_container: 2
2024-07-10 18:37:32,839:INFO:_display_container: 2
2024-07-10 18:37:32,839:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,
      precompute=False, random_state=123, selection='cyclic', tol=0.0001,
      warm_start=False)
2024-07-10 18:37:32,839:INFO:create_model() successfully completed......................................
2024-07-10 18:37:32,956:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:32,956:INFO:Creating metrics dataframe
2024-07-10 18:37:32,962:INFO:Initializing Ridge Regression
2024-07-10 18:37:32,962:INFO:Total runtime is 0.10799996058146158 minutes
2024-07-10 18:37:32,966:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:32,966:INFO:Initializing create_model()
2024-07-10 18:37:32,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:32,966:INFO:Checking exceptions
2024-07-10 18:37:32,966:INFO:Importing libraries
2024-07-10 18:37:32,966:INFO:Copying training dataset
2024-07-10 18:37:32,971:INFO:Defining folds
2024-07-10 18:37:32,971:INFO:Declaring metric variables
2024-07-10 18:37:32,973:INFO:Importing untrained model
2024-07-10 18:37:32,979:INFO:Ridge Regression Imported successfully
2024-07-10 18:37:32,986:INFO:Starting cross validation
2024-07-10 18:37:32,988:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:34,837:INFO:Calculating mean and std
2024-07-10 18:37:34,840:INFO:Creating metrics dataframe
2024-07-10 18:37:34,842:INFO:Uploading results into container
2024-07-10 18:37:34,843:INFO:Uploading model into container now
2024-07-10 18:37:34,844:INFO:_master_model_container: 3
2024-07-10 18:37:34,844:INFO:_display_container: 2
2024-07-10 18:37:34,844:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, positive=False,
      random_state=123, solver='auto', tol=0.0001)
2024-07-10 18:37:34,845:INFO:create_model() successfully completed......................................
2024-07-10 18:37:34,959:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:34,959:INFO:Creating metrics dataframe
2024-07-10 18:37:34,965:INFO:Initializing Elastic Net
2024-07-10 18:37:34,965:INFO:Total runtime is 0.1413853406906128 minutes
2024-07-10 18:37:34,968:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:34,968:INFO:Initializing create_model()
2024-07-10 18:37:34,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:34,968:INFO:Checking exceptions
2024-07-10 18:37:34,968:INFO:Importing libraries
2024-07-10 18:37:34,968:INFO:Copying training dataset
2024-07-10 18:37:34,973:INFO:Defining folds
2024-07-10 18:37:34,973:INFO:Declaring metric variables
2024-07-10 18:37:34,976:INFO:Importing untrained model
2024-07-10 18:37:34,980:INFO:Elastic Net Imported successfully
2024-07-10 18:37:34,987:INFO:Starting cross validation
2024-07-10 18:37:34,989:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:35,147:INFO:Calculating mean and std
2024-07-10 18:37:35,148:INFO:Creating metrics dataframe
2024-07-10 18:37:35,149:INFO:Uploading results into container
2024-07-10 18:37:35,150:INFO:Uploading model into container now
2024-07-10 18:37:35,150:INFO:_master_model_container: 4
2024-07-10 18:37:35,150:INFO:_display_container: 2
2024-07-10 18:37:35,151:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, positive=False, precompute=False, random_state=123,
           selection='cyclic', tol=0.0001, warm_start=False)
2024-07-10 18:37:35,151:INFO:create_model() successfully completed......................................
2024-07-10 18:37:35,265:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:35,265:INFO:Creating metrics dataframe
2024-07-10 18:37:35,270:INFO:Initializing Least Angle Regression
2024-07-10 18:37:35,270:INFO:Total runtime is 0.14647200504938762 minutes
2024-07-10 18:37:35,273:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:35,273:INFO:Initializing create_model()
2024-07-10 18:37:35,274:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:35,274:INFO:Checking exceptions
2024-07-10 18:37:35,274:INFO:Importing libraries
2024-07-10 18:37:35,274:INFO:Copying training dataset
2024-07-10 18:37:35,280:INFO:Defining folds
2024-07-10 18:37:35,280:INFO:Declaring metric variables
2024-07-10 18:37:35,284:INFO:Importing untrained model
2024-07-10 18:37:35,287:INFO:Least Angle Regression Imported successfully
2024-07-10 18:37:35,294:INFO:Starting cross validation
2024-07-10 18:37:35,296:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:35,399:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.308e+06, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-07-10 18:37:35,458:INFO:Calculating mean and std
2024-07-10 18:37:35,459:INFO:Creating metrics dataframe
2024-07-10 18:37:35,460:INFO:Uploading results into container
2024-07-10 18:37:35,461:INFO:Uploading model into container now
2024-07-10 18:37:35,462:INFO:_master_model_container: 5
2024-07-10 18:37:35,462:INFO:_display_container: 2
2024-07-10 18:37:35,462:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, precompute='auto', random_state=123,
     verbose=False)
2024-07-10 18:37:35,462:INFO:create_model() successfully completed......................................
2024-07-10 18:37:35,588:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:35,589:INFO:Creating metrics dataframe
2024-07-10 18:37:35,597:INFO:Initializing Lasso Least Angle Regression
2024-07-10 18:37:35,597:INFO:Total runtime is 0.1519277294476827 minutes
2024-07-10 18:37:35,599:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:35,600:INFO:Initializing create_model()
2024-07-10 18:37:35,600:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:35,600:INFO:Checking exceptions
2024-07-10 18:37:35,601:INFO:Importing libraries
2024-07-10 18:37:35,601:INFO:Copying training dataset
2024-07-10 18:37:35,605:INFO:Defining folds
2024-07-10 18:37:35,605:INFO:Declaring metric variables
2024-07-10 18:37:35,608:INFO:Importing untrained model
2024-07-10 18:37:35,612:INFO:Lasso Least Angle Regression Imported successfully
2024-07-10 18:37:35,617:INFO:Starting cross validation
2024-07-10 18:37:35,619:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:35,784:INFO:Calculating mean and std
2024-07-10 18:37:35,785:INFO:Creating metrics dataframe
2024-07-10 18:37:35,787:INFO:Uploading results into container
2024-07-10 18:37:35,787:INFO:Uploading model into container now
2024-07-10 18:37:35,788:INFO:_master_model_container: 6
2024-07-10 18:37:35,788:INFO:_display_container: 2
2024-07-10 18:37:35,789:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, positive=False,
          precompute='auto', random_state=123, verbose=False)
2024-07-10 18:37:35,789:INFO:create_model() successfully completed......................................
2024-07-10 18:37:35,913:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:35,913:INFO:Creating metrics dataframe
2024-07-10 18:37:35,920:INFO:Initializing Orthogonal Matching Pursuit
2024-07-10 18:37:35,920:INFO:Total runtime is 0.1573143204053243 minutes
2024-07-10 18:37:35,923:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:35,924:INFO:Initializing create_model()
2024-07-10 18:37:35,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:35,924:INFO:Checking exceptions
2024-07-10 18:37:35,924:INFO:Importing libraries
2024-07-10 18:37:35,924:INFO:Copying training dataset
2024-07-10 18:37:35,929:INFO:Defining folds
2024-07-10 18:37:35,929:INFO:Declaring metric variables
2024-07-10 18:37:35,933:INFO:Importing untrained model
2024-07-10 18:37:35,935:INFO:Orthogonal Matching Pursuit Imported successfully
2024-07-10 18:37:35,940:INFO:Starting cross validation
2024-07-10 18:37:35,944:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:36,078:INFO:Calculating mean and std
2024-07-10 18:37:36,079:INFO:Creating metrics dataframe
2024-07-10 18:37:36,080:INFO:Uploading results into container
2024-07-10 18:37:36,081:INFO:Uploading model into container now
2024-07-10 18:37:36,081:INFO:_master_model_container: 7
2024-07-10 18:37:36,081:INFO:_display_container: 2
2024-07-10 18:37:36,082:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          precompute='auto', tol=None)
2024-07-10 18:37:36,082:INFO:create_model() successfully completed......................................
2024-07-10 18:37:36,195:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:36,195:INFO:Creating metrics dataframe
2024-07-10 18:37:36,201:INFO:Initializing Bayesian Ridge
2024-07-10 18:37:36,201:INFO:Total runtime is 0.16199394861857097 minutes
2024-07-10 18:37:36,204:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:36,204:INFO:Initializing create_model()
2024-07-10 18:37:36,205:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:36,206:INFO:Checking exceptions
2024-07-10 18:37:36,206:INFO:Importing libraries
2024-07-10 18:37:36,206:INFO:Copying training dataset
2024-07-10 18:37:36,212:INFO:Defining folds
2024-07-10 18:37:36,213:INFO:Declaring metric variables
2024-07-10 18:37:36,216:INFO:Importing untrained model
2024-07-10 18:37:36,219:INFO:Bayesian Ridge Imported successfully
2024-07-10 18:37:36,224:INFO:Starting cross validation
2024-07-10 18:37:36,226:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:36,377:INFO:Calculating mean and std
2024-07-10 18:37:36,378:INFO:Creating metrics dataframe
2024-07-10 18:37:36,379:INFO:Uploading results into container
2024-07-10 18:37:36,380:INFO:Uploading model into container now
2024-07-10 18:37:36,381:INFO:_master_model_container: 8
2024-07-10 18:37:36,381:INFO:_display_container: 2
2024-07-10 18:37:36,381:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, max_iter=None,
              n_iter='deprecated', tol=0.001, verbose=False)
2024-07-10 18:37:36,381:INFO:create_model() successfully completed......................................
2024-07-10 18:37:36,496:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:36,496:INFO:Creating metrics dataframe
2024-07-10 18:37:36,502:INFO:Initializing Passive Aggressive Regressor
2024-07-10 18:37:36,502:INFO:Total runtime is 0.16701346635818481 minutes
2024-07-10 18:37:36,506:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:36,507:INFO:Initializing create_model()
2024-07-10 18:37:36,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:36,507:INFO:Checking exceptions
2024-07-10 18:37:36,507:INFO:Importing libraries
2024-07-10 18:37:36,507:INFO:Copying training dataset
2024-07-10 18:37:36,512:INFO:Defining folds
2024-07-10 18:37:36,512:INFO:Declaring metric variables
2024-07-10 18:37:36,515:INFO:Importing untrained model
2024-07-10 18:37:36,517:INFO:Passive Aggressive Regressor Imported successfully
2024-07-10 18:37:36,522:INFO:Starting cross validation
2024-07-10 18:37:36,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:36,685:INFO:Calculating mean and std
2024-07-10 18:37:36,686:INFO:Creating metrics dataframe
2024-07-10 18:37:36,687:INFO:Uploading results into container
2024-07-10 18:37:36,688:INFO:Uploading model into container now
2024-07-10 18:37:36,689:INFO:_master_model_container: 9
2024-07-10 18:37:36,689:INFO:_display_container: 2
2024-07-10 18:37:36,689:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=123, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-10 18:37:36,690:INFO:create_model() successfully completed......................................
2024-07-10 18:37:36,807:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:36,807:INFO:Creating metrics dataframe
2024-07-10 18:37:36,815:INFO:Initializing Huber Regressor
2024-07-10 18:37:36,815:INFO:Total runtime is 0.17222379446029662 minutes
2024-07-10 18:37:36,819:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:36,820:INFO:Initializing create_model()
2024-07-10 18:37:36,820:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:36,820:INFO:Checking exceptions
2024-07-10 18:37:36,820:INFO:Importing libraries
2024-07-10 18:37:36,820:INFO:Copying training dataset
2024-07-10 18:37:36,825:INFO:Defining folds
2024-07-10 18:37:36,825:INFO:Declaring metric variables
2024-07-10 18:37:36,828:INFO:Importing untrained model
2024-07-10 18:37:36,831:INFO:Huber Regressor Imported successfully
2024-07-10 18:37:36,836:INFO:Starting cross validation
2024-07-10 18:37:36,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:36,951:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-10 18:37:36,981:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-07-10 18:37:37,015:INFO:Calculating mean and std
2024-07-10 18:37:37,016:INFO:Creating metrics dataframe
2024-07-10 18:37:37,017:INFO:Uploading results into container
2024-07-10 18:37:37,018:INFO:Uploading model into container now
2024-07-10 18:37:37,018:INFO:_master_model_container: 10
2024-07-10 18:37:37,018:INFO:_display_container: 2
2024-07-10 18:37:37,019:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2024-07-10 18:37:37,019:INFO:create_model() successfully completed......................................
2024-07-10 18:37:37,135:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:37,135:INFO:Creating metrics dataframe
2024-07-10 18:37:37,142:INFO:Initializing K Neighbors Regressor
2024-07-10 18:37:37,142:INFO:Total runtime is 0.17766828934351603 minutes
2024-07-10 18:37:37,146:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:37,146:INFO:Initializing create_model()
2024-07-10 18:37:37,146:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:37,147:INFO:Checking exceptions
2024-07-10 18:37:37,147:INFO:Importing libraries
2024-07-10 18:37:37,147:INFO:Copying training dataset
2024-07-10 18:37:37,153:INFO:Defining folds
2024-07-10 18:37:37,153:INFO:Declaring metric variables
2024-07-10 18:37:37,156:INFO:Importing untrained model
2024-07-10 18:37:37,159:INFO:K Neighbors Regressor Imported successfully
2024-07-10 18:37:37,164:INFO:Starting cross validation
2024-07-10 18:37:37,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:37,400:INFO:Calculating mean and std
2024-07-10 18:37:37,402:INFO:Creating metrics dataframe
2024-07-10 18:37:37,403:INFO:Uploading results into container
2024-07-10 18:37:37,404:INFO:Uploading model into container now
2024-07-10 18:37:37,404:INFO:_master_model_container: 11
2024-07-10 18:37:37,404:INFO:_display_container: 2
2024-07-10 18:37:37,405:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2024-07-10 18:37:37,405:INFO:create_model() successfully completed......................................
2024-07-10 18:37:37,514:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:37,514:INFO:Creating metrics dataframe
2024-07-10 18:37:37,523:INFO:Initializing Decision Tree Regressor
2024-07-10 18:37:37,523:INFO:Total runtime is 0.18401769797007242 minutes
2024-07-10 18:37:37,527:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:37,527:INFO:Initializing create_model()
2024-07-10 18:37:37,528:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:37,528:INFO:Checking exceptions
2024-07-10 18:37:37,528:INFO:Importing libraries
2024-07-10 18:37:37,528:INFO:Copying training dataset
2024-07-10 18:37:37,533:INFO:Defining folds
2024-07-10 18:37:37,533:INFO:Declaring metric variables
2024-07-10 18:37:37,537:INFO:Importing untrained model
2024-07-10 18:37:37,540:INFO:Decision Tree Regressor Imported successfully
2024-07-10 18:37:37,546:INFO:Starting cross validation
2024-07-10 18:37:37,548:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:37,696:INFO:Calculating mean and std
2024-07-10 18:37:37,697:INFO:Creating metrics dataframe
2024-07-10 18:37:37,698:INFO:Uploading results into container
2024-07-10 18:37:37,699:INFO:Uploading model into container now
2024-07-10 18:37:37,699:INFO:_master_model_container: 12
2024-07-10 18:37:37,699:INFO:_display_container: 2
2024-07-10 18:37:37,700:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      monotonic_cst=None, random_state=123, splitter='best')
2024-07-10 18:37:37,700:INFO:create_model() successfully completed......................................
2024-07-10 18:37:37,810:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:37,810:INFO:Creating metrics dataframe
2024-07-10 18:37:37,818:INFO:Initializing Random Forest Regressor
2024-07-10 18:37:37,818:INFO:Total runtime is 0.18894019524256386 minutes
2024-07-10 18:37:37,821:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:37,821:INFO:Initializing create_model()
2024-07-10 18:37:37,822:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:37,822:INFO:Checking exceptions
2024-07-10 18:37:37,822:INFO:Importing libraries
2024-07-10 18:37:37,822:INFO:Copying training dataset
2024-07-10 18:37:37,827:INFO:Defining folds
2024-07-10 18:37:37,828:INFO:Declaring metric variables
2024-07-10 18:37:37,831:INFO:Importing untrained model
2024-07-10 18:37:37,833:INFO:Random Forest Regressor Imported successfully
2024-07-10 18:37:37,837:INFO:Starting cross validation
2024-07-10 18:37:37,839:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:38,415:INFO:Calculating mean and std
2024-07-10 18:37:38,416:INFO:Creating metrics dataframe
2024-07-10 18:37:38,418:INFO:Uploading results into container
2024-07-10 18:37:38,418:INFO:Uploading model into container now
2024-07-10 18:37:38,418:INFO:_master_model_container: 13
2024-07-10 18:37:38,418:INFO:_display_container: 2
2024-07-10 18:37:38,419:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, monotonic_cst=None,
                      n_estimators=100, n_jobs=-1, oob_score=False,
                      random_state=123, verbose=0, warm_start=False)
2024-07-10 18:37:38,419:INFO:create_model() successfully completed......................................
2024-07-10 18:37:38,536:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:38,536:INFO:Creating metrics dataframe
2024-07-10 18:37:38,543:INFO:Initializing Extra Trees Regressor
2024-07-10 18:37:38,543:INFO:Total runtime is 0.20102559328079223 minutes
2024-07-10 18:37:38,547:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:38,547:INFO:Initializing create_model()
2024-07-10 18:37:38,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:38,547:INFO:Checking exceptions
2024-07-10 18:37:38,548:INFO:Importing libraries
2024-07-10 18:37:38,548:INFO:Copying training dataset
2024-07-10 18:37:38,554:INFO:Defining folds
2024-07-10 18:37:38,555:INFO:Declaring metric variables
2024-07-10 18:37:38,558:INFO:Importing untrained model
2024-07-10 18:37:38,560:INFO:Extra Trees Regressor Imported successfully
2024-07-10 18:37:38,565:INFO:Starting cross validation
2024-07-10 18:37:38,567:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:39,112:INFO:Calculating mean and std
2024-07-10 18:37:39,115:INFO:Creating metrics dataframe
2024-07-10 18:37:39,117:INFO:Uploading results into container
2024-07-10 18:37:39,117:INFO:Uploading model into container now
2024-07-10 18:37:39,118:INFO:_master_model_container: 14
2024-07-10 18:37:39,118:INFO:_display_container: 2
2024-07-10 18:37:39,118:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, monotonic_cst=None,
                    n_estimators=100, n_jobs=-1, oob_score=False,
                    random_state=123, verbose=0, warm_start=False)
2024-07-10 18:37:39,118:INFO:create_model() successfully completed......................................
2024-07-10 18:37:39,228:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:39,228:INFO:Creating metrics dataframe
2024-07-10 18:37:39,235:INFO:Initializing AdaBoost Regressor
2024-07-10 18:37:39,236:INFO:Total runtime is 0.21257164478302001 minutes
2024-07-10 18:37:39,239:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:39,239:INFO:Initializing create_model()
2024-07-10 18:37:39,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:39,239:INFO:Checking exceptions
2024-07-10 18:37:39,240:INFO:Importing libraries
2024-07-10 18:37:39,240:INFO:Copying training dataset
2024-07-10 18:37:39,245:INFO:Defining folds
2024-07-10 18:37:39,245:INFO:Declaring metric variables
2024-07-10 18:37:39,249:INFO:Importing untrained model
2024-07-10 18:37:39,253:INFO:AdaBoost Regressor Imported successfully
2024-07-10 18:37:39,258:INFO:Starting cross validation
2024-07-10 18:37:39,260:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:39,531:INFO:Calculating mean and std
2024-07-10 18:37:39,533:INFO:Creating metrics dataframe
2024-07-10 18:37:39,535:INFO:Uploading results into container
2024-07-10 18:37:39,536:INFO:Uploading model into container now
2024-07-10 18:37:39,536:INFO:_master_model_container: 15
2024-07-10 18:37:39,536:INFO:_display_container: 2
2024-07-10 18:37:39,537:INFO:AdaBoostRegressor(estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=123)
2024-07-10 18:37:39,537:INFO:create_model() successfully completed......................................
2024-07-10 18:37:39,645:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:39,645:INFO:Creating metrics dataframe
2024-07-10 18:37:39,653:INFO:Initializing Gradient Boosting Regressor
2024-07-10 18:37:39,653:INFO:Total runtime is 0.21952904065450032 minutes
2024-07-10 18:37:39,655:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:39,655:INFO:Initializing create_model()
2024-07-10 18:37:39,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:39,656:INFO:Checking exceptions
2024-07-10 18:37:39,656:INFO:Importing libraries
2024-07-10 18:37:39,656:INFO:Copying training dataset
2024-07-10 18:37:39,662:INFO:Defining folds
2024-07-10 18:37:39,662:INFO:Declaring metric variables
2024-07-10 18:37:39,665:INFO:Importing untrained model
2024-07-10 18:37:39,667:INFO:Gradient Boosting Regressor Imported successfully
2024-07-10 18:37:39,672:INFO:Starting cross validation
2024-07-10 18:37:39,674:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:40,015:INFO:Calculating mean and std
2024-07-10 18:37:40,016:INFO:Creating metrics dataframe
2024-07-10 18:37:40,017:INFO:Uploading results into container
2024-07-10 18:37:40,018:INFO:Uploading model into container now
2024-07-10 18:37:40,018:INFO:_master_model_container: 16
2024-07-10 18:37:40,018:INFO:_display_container: 2
2024-07-10 18:37:40,018:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=123, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-10 18:37:40,018:INFO:create_model() successfully completed......................................
2024-07-10 18:37:40,130:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:40,130:INFO:Creating metrics dataframe
2024-07-10 18:37:40,137:INFO:Initializing Extreme Gradient Boosting
2024-07-10 18:37:40,138:INFO:Total runtime is 0.22760992844899494 minutes
2024-07-10 18:37:40,140:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:40,141:INFO:Initializing create_model()
2024-07-10 18:37:40,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:40,141:INFO:Checking exceptions
2024-07-10 18:37:40,141:INFO:Importing libraries
2024-07-10 18:37:40,141:INFO:Copying training dataset
2024-07-10 18:37:40,146:INFO:Defining folds
2024-07-10 18:37:40,146:INFO:Declaring metric variables
2024-07-10 18:37:40,148:INFO:Importing untrained model
2024-07-10 18:37:40,151:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 18:37:40,155:INFO:Starting cross validation
2024-07-10 18:37:40,157:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:41,027:INFO:Calculating mean and std
2024-07-10 18:37:41,028:INFO:Creating metrics dataframe
2024-07-10 18:37:41,029:INFO:Uploading results into container
2024-07-10 18:37:41,030:INFO:Uploading model into container now
2024-07-10 18:37:41,031:INFO:_master_model_container: 17
2024-07-10 18:37:41,031:INFO:_display_container: 2
2024-07-10 18:37:41,031:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 18:37:41,031:INFO:create_model() successfully completed......................................
2024-07-10 18:37:41,142:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:41,142:INFO:Creating metrics dataframe
2024-07-10 18:37:41,150:INFO:Initializing Light Gradient Boosting Machine
2024-07-10 18:37:41,151:INFO:Total runtime is 0.2444983641306559 minutes
2024-07-10 18:37:41,154:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:41,154:INFO:Initializing create_model()
2024-07-10 18:37:41,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:41,154:INFO:Checking exceptions
2024-07-10 18:37:41,155:INFO:Importing libraries
2024-07-10 18:37:41,155:INFO:Copying training dataset
2024-07-10 18:37:41,159:INFO:Defining folds
2024-07-10 18:37:41,160:INFO:Declaring metric variables
2024-07-10 18:37:41,162:INFO:Importing untrained model
2024-07-10 18:37:41,166:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-10 18:37:41,172:INFO:Starting cross validation
2024-07-10 18:37:41,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:42,833:INFO:Calculating mean and std
2024-07-10 18:37:42,835:INFO:Creating metrics dataframe
2024-07-10 18:37:42,836:INFO:Uploading results into container
2024-07-10 18:37:42,837:INFO:Uploading model into container now
2024-07-10 18:37:42,837:INFO:_master_model_container: 18
2024-07-10 18:37:42,837:INFO:_display_container: 2
2024-07-10 18:37:42,838:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
              subsample_for_bin=200000, subsample_freq=0)
2024-07-10 18:37:42,838:INFO:create_model() successfully completed......................................
2024-07-10 18:37:42,978:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:42,978:INFO:Creating metrics dataframe
2024-07-10 18:37:42,986:INFO:Initializing Dummy Regressor
2024-07-10 18:37:42,987:INFO:Total runtime is 0.27509562174479163 minutes
2024-07-10 18:37:42,989:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:42,989:INFO:Initializing create_model()
2024-07-10 18:37:42,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A7DD0E860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:42,989:INFO:Checking exceptions
2024-07-10 18:37:42,989:INFO:Importing libraries
2024-07-10 18:37:42,989:INFO:Copying training dataset
2024-07-10 18:37:42,993:INFO:Defining folds
2024-07-10 18:37:42,993:INFO:Declaring metric variables
2024-07-10 18:37:42,996:INFO:Importing untrained model
2024-07-10 18:37:42,999:INFO:Dummy Regressor Imported successfully
2024-07-10 18:37:43,004:INFO:Starting cross validation
2024-07-10 18:37:43,006:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:43,154:INFO:Calculating mean and std
2024-07-10 18:37:43,155:INFO:Creating metrics dataframe
2024-07-10 18:37:43,157:INFO:Uploading results into container
2024-07-10 18:37:43,158:INFO:Uploading model into container now
2024-07-10 18:37:43,159:INFO:_master_model_container: 19
2024-07-10 18:37:43,159:INFO:_display_container: 2
2024-07-10 18:37:43,159:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2024-07-10 18:37:43,159:INFO:create_model() successfully completed......................................
2024-07-10 18:37:43,269:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:43,269:INFO:Creating metrics dataframe
2024-07-10 18:37:43,281:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-07-10 18:37:43,288:INFO:Initializing create_model()
2024-07-10 18:37:43,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:43,288:INFO:Checking exceptions
2024-07-10 18:37:43,289:INFO:Importing libraries
2024-07-10 18:37:43,290:INFO:Copying training dataset
2024-07-10 18:37:43,294:INFO:Defining folds
2024-07-10 18:37:43,294:INFO:Declaring metric variables
2024-07-10 18:37:43,294:INFO:Importing untrained model
2024-07-10 18:37:43,294:INFO:Declaring custom model
2024-07-10 18:37:43,295:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 18:37:43,296:INFO:Cross validation set to False
2024-07-10 18:37:43,296:INFO:Fitting Model
2024-07-10 18:37:43,476:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 18:37:43,476:INFO:create_model() successfully completed......................................
2024-07-10 18:37:43,620:INFO:_master_model_container: 19
2024-07-10 18:37:43,621:INFO:_display_container: 2
2024-07-10 18:37:43,621:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 18:37:43,621:INFO:compare_models() successfully completed......................................
2024-07-10 18:37:43,623:INFO:Initializing create_model()
2024-07-10 18:37:43,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:43,623:INFO:Checking exceptions
2024-07-10 18:37:43,633:INFO:Importing libraries
2024-07-10 18:37:43,633:INFO:Copying training dataset
2024-07-10 18:37:43,637:INFO:Defining folds
2024-07-10 18:37:43,637:INFO:Declaring metric variables
2024-07-10 18:37:43,639:INFO:Importing untrained model
2024-07-10 18:37:43,639:INFO:Declaring custom model
2024-07-10 18:37:43,642:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 18:37:43,649:INFO:Starting cross validation
2024-07-10 18:37:43,651:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:44,440:INFO:Calculating mean and std
2024-07-10 18:37:44,441:INFO:Creating metrics dataframe
2024-07-10 18:37:44,445:INFO:Finalizing model
2024-07-10 18:37:44,618:INFO:Uploading results into container
2024-07-10 18:37:44,619:INFO:Uploading model into container now
2024-07-10 18:37:44,626:INFO:_master_model_container: 20
2024-07-10 18:37:44,626:INFO:_display_container: 3
2024-07-10 18:37:44,627:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 18:37:44,627:INFO:create_model() successfully completed......................................
2024-07-10 18:37:44,770:INFO:Initializing tune_model()
2024-07-10 18:37:44,770:INFO:tune_model(estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>)
2024-07-10 18:37:44,770:INFO:Checking exceptions
2024-07-10 18:37:44,782:INFO:Copying training dataset
2024-07-10 18:37:44,786:INFO:Checking base model
2024-07-10 18:37:44,786:INFO:Base model : Extreme Gradient Boosting
2024-07-10 18:37:44,790:INFO:Declaring metric variables
2024-07-10 18:37:44,792:INFO:Defining Hyperparameters
2024-07-10 18:37:44,906:INFO:Tuning with n_jobs=-1
2024-07-10 18:37:44,907:INFO:Initializing RandomizedSearchCV
2024-07-10 18:37:47,115:INFO:best_params: {'actual_estimator__subsample': 0.2, 'actual_estimator__scale_pos_weight': 37.7, 'actual_estimator__reg_lambda': 0.2, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__n_estimators': 220, 'actual_estimator__min_child_weight': 4, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__colsample_bytree': 0.9}
2024-07-10 18:37:47,116:INFO:Hyperparameter search completed
2024-07-10 18:37:47,116:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:47,116:INFO:Initializing create_model()
2024-07-10 18:37:47,117:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A1689AC80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.2, 'scale_pos_weight': 37.7, 'reg_lambda': 0.2, 'reg_alpha': 0.0001, 'n_estimators': 220, 'min_child_weight': 4, 'max_depth': 10, 'learning_rate': 0.05, 'colsample_bytree': 0.9})
2024-07-10 18:37:47,117:INFO:Checking exceptions
2024-07-10 18:37:47,117:INFO:Importing libraries
2024-07-10 18:37:47,117:INFO:Copying training dataset
2024-07-10 18:37:47,123:INFO:Defining folds
2024-07-10 18:37:47,123:INFO:Declaring metric variables
2024-07-10 18:37:47,125:INFO:Importing untrained model
2024-07-10 18:37:47,126:INFO:Declaring custom model
2024-07-10 18:37:47,130:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 18:37:47,134:INFO:Starting cross validation
2024-07-10 18:37:47,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:47,520:INFO:Calculating mean and std
2024-07-10 18:37:47,521:INFO:Creating metrics dataframe
2024-07-10 18:37:47,525:INFO:Finalizing model
2024-07-10 18:37:47,941:INFO:Uploading results into container
2024-07-10 18:37:47,942:INFO:Uploading model into container now
2024-07-10 18:37:47,942:INFO:_master_model_container: 21
2024-07-10 18:37:47,942:INFO:_display_container: 4
2024-07-10 18:37:47,943:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.05, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=10, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=220, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 18:37:47,943:INFO:create_model() successfully completed......................................
2024-07-10 18:37:48,069:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:48,069:INFO:choose_better activated
2024-07-10 18:37:48,072:INFO:SubProcess create_model() called ==================================
2024-07-10 18:37:48,072:INFO:Initializing create_model()
2024-07-10 18:37:48,072:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-10 18:37:48,073:INFO:Checking exceptions
2024-07-10 18:37:48,074:INFO:Importing libraries
2024-07-10 18:37:48,074:INFO:Copying training dataset
2024-07-10 18:37:48,077:INFO:Defining folds
2024-07-10 18:37:48,077:INFO:Declaring metric variables
2024-07-10 18:37:48,077:INFO:Importing untrained model
2024-07-10 18:37:48,077:INFO:Declaring custom model
2024-07-10 18:37:48,078:INFO:Extreme Gradient Boosting Imported successfully
2024-07-10 18:37:48,078:INFO:Starting cross validation
2024-07-10 18:37:48,080:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-10 18:37:48,342:INFO:Calculating mean and std
2024-07-10 18:37:48,343:INFO:Creating metrics dataframe
2024-07-10 18:37:48,345:INFO:Finalizing model
2024-07-10 18:37:48,523:INFO:Uploading results into container
2024-07-10 18:37:48,524:INFO:Uploading model into container now
2024-07-10 18:37:48,524:INFO:_master_model_container: 22
2024-07-10 18:37:48,524:INFO:_display_container: 5
2024-07-10 18:37:48,525:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 18:37:48,525:INFO:create_model() successfully completed......................................
2024-07-10 18:37:48,649:INFO:SubProcess create_model() end ==================================
2024-07-10 18:37:48,650:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...) result for R2 is 0.7198
2024-07-10 18:37:48,651:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=0.9, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.05, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=10, max_leaves=None,
             min_child_weight=4, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=220, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...) result for R2 is 0.634
2024-07-10 18:37:48,651:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...) is best model
2024-07-10 18:37:48,651:INFO:choose_better completed
2024-07-10 18:37:48,651:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-10 18:37:48,659:INFO:_master_model_container: 22
2024-07-10 18:37:48,659:INFO:_display_container: 4
2024-07-10 18:37:48,659:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...)
2024-07-10 18:37:48,659:INFO:tune_model() successfully completed......................................
2024-07-10 18:37:48,778:INFO:Initializing predict_model()
2024-07-10 18:37:48,778:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000014A7DADB190>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device='cpu', early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=None, n_jobs=-1,
             num_parallel_tree=None, objective='reg:squarederror', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000014A7D938280>)
2024-07-10 18:37:48,778:INFO:Checking exceptions
2024-07-10 18:37:48,778:INFO:Preloading libraries
2024-07-10 18:37:48,913:WARNING:c:\Users\Admin\miniconda3\envs\gumi_env310\lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

